{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLRH_Preprocessing_Complete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Enrico-Call/RL-AKI/blob/main/2_Data_Aggregation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/AmsterdamUMC/AmsterdamUMCdb/blob/master/img/logo_amds.png?raw=1\" alt=\"Logo\" width=128px/>\n",
        "\n",
        "# VUmc Research Project - Reinforcement Learning for Sepsis Prevention\n",
        "# Data Aggregation\n",
        "\n",
        "AmsterdamUMCdb version 1.0.2 March 2020  \n",
        "Copyright &copy; 2003-2022 Amsterdam UMC - Amsterdam Medical Data Science"
      ],
      "metadata": {
        "id": "V02CVVzdNfej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Set up the environment variables for Colab and GoogleBigQuery to access"
      ],
      "metadata": {
        "id": "R96zGqRiNpek"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0L2i-Nnp7_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4729599a-391b-40dc-b461-c9ce76d29c56"
      },
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        "from IPython.display import display\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('use_inf_as_na', True)\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('/content/drive/MyDrive/MLRFH')\n",
        " \n",
        "#sets dateset\n",
        "PROJECT_ID = 'rl-aki'\n",
        "DATASET_ID = 'version1_0_2'\n",
        "LOCATION = 'eu'\n",
        " \n",
        "#all libraries check this environment variable, so set it:\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        " \n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define Preprocessing Functions"
      ],
      "metadata": {
        "id": "oHbqYVb-N6v_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyva7EbsU_yt"
      },
      "source": [
        "#Some preprocessing functions \n",
        "\n",
        "def to_cols(data):\n",
        "\n",
        "  grouped = data.pivot_table(index=['admissionid', 'time'], \n",
        "          columns=['item'], values='value')\n",
        "\n",
        "  return grouped\n",
        "  \n",
        "\n",
        "def to_cols_action(data):\n",
        "\n",
        "  grouped = data.pivot_table(index=['admissionid', 'time'], \n",
        "            columns=['item'], values='administered')\n",
        "\n",
        "  return grouped\n",
        "\n",
        "def remove_outliers(data):\n",
        "  #delete outliers\n",
        "  data = data.reset_index() #return to single index\n",
        "\n",
        "  #select outlier cols\n",
        "  all_cols = ['Kreatinine', 'Kreatinine (bloed)', 'KREAT enzym. (bloed)',\n",
        "       'UrineSupraPubis', 'UrineIncontinentie', 'Nefrodrain re Uit',\n",
        "       'Nefrodrain li Uit', 'UrineSpontaan', 'UrineUP', 'UrineSplint Re',\n",
        "       'UrineSplint Li', 'UrineCAD', 'Chloor (bloed)', 'Natrium (bloed)',\n",
        "       'Kalium (bloed)', 'HCO3', 'Natrium', 'Natrium Astrup',\n",
        "       'Kalium Astrup', 'Chloor Astrup', 'Chloor', 'Kalium',\n",
        "       'Act.HCO3 (bloed)', 'Na (onv.ISE) (bloed)', 'K (onv.ISE) (bloed)',\n",
        "       'Cl (onv.ISE) (bloed)', 'Niet invasieve bloeddruk gemiddeld',\n",
        "       'ABP gemiddeld II', 'ABP gemiddeld']\n",
        "  \n",
        "  # Natrium\n",
        "  data['Natrium'][(data['Natrium'] < 65.) & (data['Natrium'] > 165.)] = np.nan\n",
        "  data['Natrium (bloed)'][(data['Natrium (bloed)'] < 65.) & (data['Natrium (bloed)'] > 165.)] = np.nan\n",
        "  data['Natrium Astrup'][(data['Natrium Astrup'] < 65.) & (data['Natrium Astrup'] > 165.)] = np.nan\n",
        "  data['Na (onv.ISE) (bloed)'][(data['Na (onv.ISE) (bloed)'] < 65.) & (data['Na (onv.ISE) (bloed)'] > 165.)] = np.nan\n",
        "  \n",
        "  # Mean Blood Pressure\n",
        "  data['ABP gemiddeld'][(data['ABP gemiddeld'] < 30.) & (data['ABP gemiddeld'] > 165.)] = np.nan\n",
        "  data['Niet invasieve bloeddruk gemiddeld'][(data['Niet invasieve bloeddruk gemiddeld'] < 30.) & (data['Niet invasieve bloeddruk gemiddeld'] > 165.)] = np.nan\n",
        "  data['ABP gemiddeld II'][(data['ABP gemiddeld II'] < 30) & (data['ABP gemiddeld II'] > 165)]\n",
        "\n",
        "  # Kalium\n",
        "  data['Kalium'][data['Kalium'] > 12.] = np.nan\n",
        "  data['Kalium (bloed)'][data['Kalium (bloed)'] > 12.] = np.nan\n",
        "  data['Kalium Astrup'][data['Kalium Astrup'] > 12.] = np.nan\n",
        "  data['K (onv.ISE) (bloed)'][data['K (onv.ISE) (bloed)'] > 12.] = np.nan\n",
        "\n",
        "  # Kreatinine\n",
        "  data['Kreatinine'][data['Kreatinine'] < 30.] = np.nan\n",
        "  data['Kreatinine (bloed)'][data['Kreatinine (bloed)'] < 30.] = np.nan\n",
        "  data['KREAT enzym. (bloed)'][data['KREAT enzym. (bloed)'] < 30.] = np.nan\n",
        "\n",
        "  # Bicarbonate\n",
        "\n",
        "  # Chloor\n",
        "\n",
        "  #make nans of all negative vals\n",
        "  data[all_cols] = data[all_cols].applymap(lambda x: np.nan if x < 0 else x)\n",
        "  return data\n",
        "\n",
        "\n",
        "def remove_outliers_action(data):\n",
        "\n",
        "  #delete outliers\n",
        "  outliers = data.reset_index() #return to single index\n",
        "\n",
        "  cols = ['Noradrenaline (Norepinefrine)', 'NaCl 0,45%/Glucose 2,5%']\n",
        "\n",
        "  #select outlier cols\n",
        "  data['Noradrenaline (Norepinefrine)'][data['Noradrenaline (Norepinefrine)'] > 10.] = np.nan\n",
        "  data['NaCl 0,45%/Glucose 2,5%'][data['NaCl 0,45%/Glucose 2,5%'] > 500.] = np.nan\n",
        "  \n",
        "\n",
        "  data = data[cols].applymap(lambda x: np.nan if x < 0 else x)\n",
        "\n",
        "  return data\n",
        "\n",
        "def get_4h(data):\n",
        "  #per patient, average the values in 4h timeslots\n",
        "\n",
        "  data = data.sort_values('time')\n",
        "  res = data.groupby([pd.Grouper('admissionid'),\n",
        "                        pd.Grouper(key ='time', freq='4H')\n",
        "                              \n",
        "  ]).mean()\n",
        "\n",
        "  return res\n",
        "\n",
        "def get_4h_urine(data):\n",
        "  #per patient, average the values in 4h timeslots\n",
        "\n",
        "  data = data.sort_values('time')\n",
        "  res = data.groupby([pd.Grouper('admissionid'),\n",
        "                        pd.Grouper(key ='time', freq='4H')\n",
        "                              \n",
        "  ]).sum()\n",
        "\n",
        "  return res\n",
        "\n",
        "def aggregate_col(data, colname):\n",
        "\n",
        "  #create new columns with cumulative count for consecutive nans\n",
        "  data['nancount'] = np.zeros(len(data))\n",
        "  data['nancount'] = data[colname].groupby((data[colname].notnull()).cumsum()).cumcount()\n",
        "                           \n",
        "  #manually set first row to 1 if nan since this is excluded in cumsum/count from line before\n",
        "  for i, v in enumerate(data[colname]):\n",
        "    if i == 0:\n",
        "      if np.isnan(v):\n",
        "        data[\"nancount\"] += 1\n",
        "  \n",
        "  #and all other ones +1, except non-nan values\n",
        "  data[\"nancount\"][data[colname] == np.nan] += 1\n",
        "\n",
        "  #set non-null values as 0 for nancount\n",
        "  data[\"nancount\"] = np.where(~data[colname].isnull(), 0, data[\"nancount\"])\n",
        "\n",
        "  #if value is not nan, then use previous value + 1 to get total cumulative nan count including the non-nan value\n",
        "  #this is the value we want to divide through to get the right value per hour\n",
        "\n",
        "  group_val = pd.DataFrame(data[colname]).reset_index()[colname]\n",
        "  group_count = pd.DataFrame(data[\"nancount\"]).reset_index()[\"nancount\"]\n",
        "\n",
        "  for i, v in enumerate(group_count):\n",
        "\n",
        "    if v == 0: #where no null values\n",
        " \n",
        "      if (i != 0): #first row: do nothing\n",
        "        if group_val[i] != 0: #value 0: do not divide\n",
        "          if group_count[i-1] != 0: #value before is not missing: do nothing\n",
        "          \n",
        "            group_val[i] = group_val[i] / (group_count[i-1]) #otherwise: divide through nancount of row before\n",
        "  \n",
        "\n",
        "  #and then fill backwards and return\n",
        "  return group_val.bfill()\n",
        "\n",
        "def sum_urine(data):\n",
        "  # urine_cols = ['UrineCAD']\n",
        "  urine_cols = ['UrineCAD', 'UrineSupraPubis', 'UrineUP', 'UrineSpontaan', 'UrineIncontinentie', 'UrineSplint Re', 'UrineSplint Li']\n",
        "  data['Urine_summed'] = data[urine_cols].sum(axis=1)\n",
        "  data['Urine_summed'] = np.where(data['Urine_summed'] == 0, np.nan, data['Urine_summed'])\n",
        "  return data.drop(columns=urine_cols)\n",
        "\n",
        "def aggregate_all_cols(data, space):\n",
        "\n",
        "  if space == 'state':\n",
        "\n",
        "    cols_to_agg = ['time', 'admissionid', 'Kreatinine', 'Kreatinine (bloed)', 'KREAT enzym. (bloed)',\n",
        "       'Chloor (bloed)', 'Natrium (bloed)',\n",
        "       'Kalium (bloed)', 'HCO3', 'Natrium', 'Natrium Astrup',\n",
        "       'Kalium Astrup', 'Chloor Astrup', 'Chloor', 'Kalium',\n",
        "       'Act.HCO3 (bloed)', 'Na (onv.ISE) (bloed)', 'K (onv.ISE) (bloed)',\n",
        "       'Cl (onv.ISE) (bloed)', 'Niet invasieve bloeddruk gemiddeld',\n",
        "       'ABP gemiddeld II', 'ABP gemiddeld']\n",
        "\n",
        "    #group urine (sum)\n",
        "    grouped = data.groupby('admissionid', as_index = False).apply(lambda x: aggregate_col(x, 'Urine_summed')).reset_index()['Urine_summed']\n",
        "    data['Urine'] = list(grouped.head(len(grouped)))\n",
        "    data = pd.DataFrame(data).reset_index()\n",
        "    urine_aggr = get_4h_urine(data[['admissionid', 'time', 'Urine']])\n",
        "\n",
        "    #group other variables (mean)\n",
        "    data[cols_to_agg] = data[cols_to_agg].bfill()\n",
        "    df_aggr = get_4h(data[cols_to_agg])\n",
        "\n",
        "    #combine both aggregations\n",
        "    combined = pd.concat([urine_aggr, df_aggr], axis=1)\n",
        "\n",
        "    return combined\n",
        "\n",
        "  if space == 'action':\n",
        "\n",
        "    data = data.reset_index()\n",
        "    cols_to_agg = ['time', 'admissionid', 'Dobutamine (Dobutrex)',\n",
        "                   'Adrenaline (Epinefrine)', 'Dopamine (Inotropin)',\n",
        "                   'Noradrenaline (Norepinefrine)', 'NaCl 0,45%/Glucose 2,5%']\n",
        "    data[cols_to_agg] = data[cols_to_agg].bfill()\n",
        "    df_aggr = get_4h(data[cols_to_agg])\n",
        "\n",
        "    return df_aggr\n",
        "\n",
        "  else:\n",
        "\n",
        "    print(\"ERROR INVALID SPACE TYPE: options for space: state, action\")\n",
        "\n",
        "\n",
        "def interpolate(data_agg):\n",
        "  #interpolate null values\n",
        "  return data_agg.interpolate(limit_direction='forward')\n",
        "\n",
        "def transform_df(data: pd.DataFrame = None,\n",
        "                 time_col: str = 'time',\n",
        "                 bins: list = None,\n",
        "                 bin_labels: list = None,\n",
        "                 group_cols: list = ['admissionid', 'binn'],\n",
        "                 agg_func: dict = None):\n",
        "    \"\"\"\n",
        "    Transforms the input data from the AmsterdamUMCdb and return a dataframe with bins assigned to each record based on the time column\n",
        "    :param data: dataframe with single timestamps as integers, patientid and values\n",
        "    :param bins: list of bins to divide the timestamps in\n",
        "    :param bin_labels: list of labels to name the bins with\n",
        "    :param group_cols: list of column to group by, including the newly created 'binn'\n",
        "    :param agg_func: dictionary of kwargs passed to the .agg() method\n",
        "    \"\"\"\n",
        "    \n",
        "    data['binn'] = pd.cut(data[time_col], bins=bins, labels=bin_labels)\n",
        "    data = data[data[time_col]>=0]\n",
        "    grouped_data = data.groupby(group_cols).agg(**agg_func).reset_index().sort_values(by=group_cols, ascending=True)\n",
        "    \n",
        "    return grouped_data\n",
        "\n",
        "\n",
        "def transform_daterange(data: pd.DataFrame,\n",
        "                        time_col: str = 'time',\n",
        "                        infer_start_time: bool = True,\n",
        "                        multi_source: bool = False,\n",
        "                        multi_source_col: str = None,\n",
        "                        start_time: str = 'start_time',\n",
        "                        end_time: str = 'end_time',\n",
        "                        time_unit: str = 'm',\n",
        "                        value_col: str = 'value',\n",
        "                        group_col: list = None,\n",
        "                        fill_method: str = 'backfill',\n",
        "                        fill_lim: int = 540\n",
        "                        ):\n",
        "    \"\"\"\n",
        "    Transform interval data with single timestamps to time range, calculate production, resample and backward fill\n",
        "    :param data: dataframe with id, value and timestamp\n",
        "    :param time_col: string representing the column name for the time of registration in a single timestamp dataframe\n",
        "    :param infer_start_time: boolean representing whether the start time should be inferred from the previous record\n",
        "    :param start_time: string representing the column name with the record start time\n",
        "    :param end_time: string representing the column name with the record end time\n",
        "    :param time_unit: interpret the integer timestamp as the given time unit and convert back to this unit at the end\n",
        "    :param value_col: string representing the column name with the values of the measurements\n",
        "    :param group_col: list representing the ids of patients and/or products\n",
        "    :param fill_method: string to represent the method as used in pandas.series.fillna\n",
        "    :param fill_lim: integer to represent the number of time units to be filled\n",
        "    \"\"\"\n",
        "    \n",
        "    if group_col is None:\n",
        "        group_col = ['admissionid'] # PM: defining a list as default will keep alterations when rerunning the function\n",
        "    \n",
        "    # convert to datetime and set index to time column\n",
        "    data[time_col] = pd.to_datetime(data[time_col], unit=time_unit)\n",
        "    data[start_time] = pd.to_datetime(data[start_time], unit=time_unit)\n",
        "    \n",
        "    if infer_start_time:\n",
        "        # get start time from previous record\n",
        "        data['start_time'] = data.groupby(group_col)[time_col].shift(1)\n",
        "        start_time = 'start_time'\n",
        "        end_time = time_col\n",
        "    else:\n",
        "        # transform other columns to datetime if they exist and are still integer type, otherwise leave as is\n",
        "        for t_col in [start_time, end_time]:\n",
        "            if t_col in data:\n",
        "                if pd.api.types.is_integer_dtype(data[start_time]):\n",
        "                    data[t_col] = pd.to_datetime(data[t_col], unit=time_unit)\n",
        "    \n",
        "    # get time difference from start and end times   \n",
        "    data['time_diff'] = (data[end_time] - data[start_time]) / np.timedelta64(1, time_unit)\n",
        "\n",
        "    if multi_source:\n",
        "        if multi_source_col is None:\n",
        "            # give each record a unique id to group by in order to handle simultaneous records\n",
        "            data['administrationid'] = range(data.shape[0])\n",
        "            group_col += ['administrationid']\n",
        "        else:\n",
        "            group_col += [multi_source_col]\n",
        "    \n",
        "    # get production per time unit\n",
        "    data['prod'] = data[value_col] / data['time_diff']\n",
        "    \n",
        "    # if start and end time are registered in the same record, create a new record with the other value as index\n",
        "    if infer_start_time:\n",
        "        data_merged = data.copy()\n",
        "        data_merged.index = data_merged[time_col]\n",
        "    else:\n",
        "        data_end = data.copy()\n",
        "        data.index = data.start_time\n",
        "        data_end.index = data_end.stop_time\n",
        "        data_merged = pd.concat([data, data_end]).sort_values(group_col + [start_time, end_time])\n",
        "    \n",
        "    # resample for each unit\n",
        "    res = data_merged[group_col + ['prod', start_time, end_time]].groupby(group_col).resample('1T').mean().drop(group_col, axis=1, errors='ignore').reset_index().copy()\n",
        "    \n",
        "    # fill missing values\n",
        "    res['prod_fill'] = res.groupby(group_col)['prod'].fillna(method=fill_method, limit=fill_lim) #9 hours\n",
        "    \n",
        "    # reset time column to integer values\n",
        "    transform_time_col = {'s': 1, 'm': 60, 'h': 3600, 'd': 86_400}\n",
        "    if infer_start_time:\n",
        "        res[time_col] = (res[time_col].view(np.int64) / (transform_time_col.get(time_unit) * 1_000_000_000)).astype(int)\n",
        "    else:\n",
        "        if multi_source:\n",
        "            level_col = 'level_2'\n",
        "        else:\n",
        "            level_col = 'level_1'\n",
        "        res[time_col] = (res[level_col].view(np.int64) / (transform_time_col.get(time_unit) * 1_000_000_000)).astype(int)\n",
        "    \n",
        "    return res\n",
        "    \n",
        "\n",
        "def get_demograhics(data, admissionid):\n",
        "  # Get gender\n",
        "  genders = data[['admissionid', 'gender']].dropna()\n",
        "  try:\n",
        "    gender = genders['gender'][genders['admissionid'] == admissionid].head(1).item()\n",
        "    if gender == 'Man':\n",
        "      gender = 0\n",
        "    if gender == 'Vrouw':\n",
        "      gender = 1\n",
        "  except ValueError:\n",
        "    gender = \"Unknown\"\n",
        "\n",
        "  # Get Age\n",
        "  age = data['agegroup'][data['admissionid'] == admissionid].head(1).item()\n",
        "\n",
        "  # Get Weight\n",
        "  weight = data['weightgroup'][data['admissionid'] == admissionid].head(1).item()\n",
        "\n",
        "  # Get Height\n",
        "  height = data['heightgroup'][data['admissionid'] == admissionid].head(1).item()\n",
        "\n",
        "  # Get PatientID\n",
        "  patientID = data['patientid'][data['admissionid'] == admissionid].head(1).item()\n",
        "\n",
        "  # Get Date of Death\n",
        "  death = data['dateofdeath'][data['admissionid'] == admissionid].head(1).item()\n",
        "  if death == np.nan:\n",
        "    death = 0\n",
        "  else:\n",
        "    death = 1\n",
        "\n",
        "  return gender, age, weight, height, patientID, death\n",
        "\n",
        "\n",
        "def complete_state(data, df):\n",
        "  data = data.sort_values(by=['admissionid', 'time']).reset_index()\n",
        "  genders = ages = weights = heights = patientids = deaths = []\n",
        "\n",
        "  # Get demographics for each admission id\n",
        "  for x in data['admissionid']:\n",
        "    gender, age, weight, height, patientID, death = get_demograhics(df, x)\n",
        "    genders.append(gender)\n",
        "    ages.append(age)\n",
        "    weights.append(weight)\n",
        "    heights.append(height)\n",
        "    patientids.append(patientID)\n",
        "    deaths.append(death)\n",
        "\n",
        "  data['gender'] = genders\n",
        "  data['agegroup'] = ages\n",
        "  data['weightgroup'] = weights\n",
        "  data['heightgroup'] = heights\n",
        "  data['patientid'] = patientids\n",
        "  data['death'] = deaths\n",
        "\n",
        "  # Transform categorical variables into numerical\n",
        "  categories = {\"agegroup\": {\"18-39\": 1, \"40-49\": 2, \"50-59\": 3, \"60-69\":4, \"70-79\":5, \"80+\":6}, \n",
        "          \"weightgroup\": {'59-': 1,'60-69': 2, '80-89': 3, '70-79': 4, '90-99': 5, '100-109': 6, '110+': 7}, \n",
        "          \"heightroup\": {'159-': 1, '160-169': 2, '170-179': 3, '180-189': 4, '190+': 5}}\n",
        "  data = data.replace(categories)\n",
        "  \n",
        "  return data\n",
        "\n",
        "\n",
        "def process_statespace(data):\n",
        "  data['time'] = pd.to_datetime(data['time'], unit='m', origin = 'unix')\n",
        "  grouped = to_cols(data)\n",
        "  grouped = remove_outliers(grouped)\n",
        "  data_sum = sum_urine(grouped)\n",
        "  data_agg = aggregate_all_cols(data_sum, space=\"state\")\n",
        "  data_agg = complete_state(data_agg, data)\n",
        "  #data_filled = interpolate(data_agg)\n",
        "  # return data_agg.reset_index()\n",
        "  return data_agg\n",
        "\n",
        "  \n",
        "def process_actionspace(data):\n",
        "  # data['time'] = pd.to_datetime(data['stop'] - data['start'], unit='ms')\n",
        "  # data = data.drop(columns = ['start', 'stop'])\n",
        "  # data['time'] = pd.to_datetime(data['time'], unit='ms', origin = 'unix')\n",
        "  # grouped = to_cols_action(data)\n",
        "  # #grouped = remove_outliers_action(grouped)\n",
        "  # data_agg = aggregate_all_cols(grouped, space=\"action\")\n",
        "  # #data_filled = interpolate(data_agg)\n",
        "\n",
        "  # Extract Fluids and Vasopressors\n",
        "  fluids = data.loc[~data['itemid'].isin([7179,7178,6818,7229])]\n",
        "  vasop = data.loc[data['itemid'].isin([7179,7178,6818,7229])]\n",
        "  \n",
        "  # Perform Aggregation\n",
        "  df_aggr_fluids = transform_df(data=transform_daterange(fluids[['admissionid',\n",
        "                                                                 'fluidin',\n",
        "                                                                 'start_time',\n",
        "                                                                 'stop_time']].sort_values(['admissionid', 'start_time']).copy(),\n",
        "                                                     time_col = 'stop_time',\n",
        "                                                     infer_start_time=False,\n",
        "                                                     multi_source=False,\n",
        "                                                     start_time = 'start_time',\n",
        "                                                     end_time = 'stop_time',\n",
        "                                                     value_col = 'fluidin',\n",
        "                                                     group_col = ['admissionid']),\n",
        "                                 time_col='stop_time',\n",
        "                                 bins=range(0, 76*60, 4*60),\n",
        "                                 bin_labels=range(0, 72*60, 4*60),\n",
        "                                 group_cols=['admissionid', 'binn'],\n",
        "                                 agg_func={'fluid_sum': ('prod_fill', 'sum')})\n",
        "  df_aggr_vasops = transform_df(data=transform_daterange(vasop[['admissionid',\n",
        "                                                                 'fluidin',\n",
        "                                                                 'start_time',\n",
        "                                                                 'stop_time']].sort_values(['admissionid', 'start_time']).copy(),\n",
        "                                                     time_col = 'stop_time',\n",
        "                                                     infer_start_time=False,\n",
        "                                                     multi_source=False,\n",
        "                                                     start_time = 'start_time',\n",
        "                                                     end_time = 'stop_time',\n",
        "                                                     value_col = 'fluidin',\n",
        "                                                     group_col = ['admissionid']),\n",
        "                                 time_col='stop_time',\n",
        "                                 bins=range(0, 76*60, 4*60),\n",
        "                                 bin_labels=range(0, 72*60, 4*60),\n",
        "                                 group_cols=['admissionid', 'binn'],\n",
        "                                 agg_func={'vasops_sum': ('prod_fill', 'sum')})\n",
        "    \n",
        "  df_aggr_fluids['fluid_sum'] = df_aggr_fluids['fluid_sum'].fillna(0)\n",
        "  df_aggr_vasops['vasops_sum'] = df_aggr_vasops['vasops_sum'].fillna(0)\n",
        "\n",
        "  return pd.merge(df_aggr_fluids, df_aggr_vasops, how='outer', on=['admissionid', 'binn'])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Import Dataframes and Perform Aggregation"
      ],
      "metadata": {
        "id": "JZzls00gOCbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "statespace = pd.read_csv('final_state_space.csv')\n",
        "actionspace = pd.read_csv('final_action_space.csv')\n",
        "\n",
        "state = process_statespace(statespace)\n",
        "action = process_actionspace(actionspace)"
      ],
      "metadata": {
        "id": "RmV76_AOCy47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "ab1c344f-1c01-45ed-eccb-e0d24cdfd990"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-74c72fd40815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mactionspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_action_space.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_statespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# action = process_actionspace(actionspace)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-162d7041da0c>\u001b[0m in \u001b[0;36mprocess_statespace\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[0mdata_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_urine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m   \u001b[0mdata_agg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_all_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m   \u001b[0mdata_agg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_agg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m   \u001b[0;31m#data_filled = interpolate(data_agg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m   \u001b[0;31m# return data_agg.reset_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-162d7041da0c>\u001b[0m in \u001b[0;36mcomplete_state\u001b[0;34m(data, df)\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[0;31m# Get demographics for each admission id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'admissionid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0mgender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatientID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_demograhics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0mgenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-162d7041da0c>\u001b[0m in \u001b[0;36mget_demograhics\u001b[0;34m(data, admissionid)\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0mgenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'admissionid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mgender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'admissionid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0madmissionid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgender\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Man'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m       \u001b[0mgender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5501\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5502\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "2l4is9QU6APL",
        "outputId": "33fbf6f6-a6fc-4bc8-a91e-1574daf93f4f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "item   admissionid                time       Urine  Kreatinine  \\\n",
              "0               11 1970-01-01 00:00:00   10.666667       439.0   \n",
              "1               11 1970-01-01 04:00:00   10.666667       439.0   \n",
              "2               11 1970-01-01 08:00:00   10.666667       439.0   \n",
              "3               11 1970-01-01 12:00:00    9.633333       439.0   \n",
              "4               11 1970-01-01 16:00:00   15.500000       439.0   \n",
              "...            ...                 ...         ...         ...   \n",
              "43841        23545 1970-01-03 04:00:00  440.000000         NaN   \n",
              "43842        23545 1970-01-03 08:00:00  310.000000         NaN   \n",
              "43843        23545 1970-01-03 12:00:00  595.000000         NaN   \n",
              "43844        23545 1970-01-03 16:00:00  570.000000         NaN   \n",
              "43845        23545 1970-01-03 20:00:00  420.000000         NaN   \n",
              "\n",
              "item   Kreatinine (bloed)  KREAT enzym. (bloed)  Chloor (bloed)  \\\n",
              "0                   342.2                 331.0          107.20   \n",
              "1                   337.0                 331.0          108.40   \n",
              "2                   316.0                 331.0          107.00   \n",
              "3                   302.0                 331.0          108.25   \n",
              "4                   302.0                 331.0          105.60   \n",
              "...                   ...                   ...             ...   \n",
              "43841                55.0                   NaN             NaN   \n",
              "43842                 NaN                   NaN             NaN   \n",
              "43843                 NaN                   NaN             NaN   \n",
              "43844                 NaN                   NaN             NaN   \n",
              "43845                 NaN                   NaN             NaN   \n",
              "\n",
              "item   Natrium (bloed)  Kalium (bloed)  HCO3  ...  Chloor Astrup  Chloor  \\\n",
              "0                138.4            4.32  23.9  ...            1.0   102.0   \n",
              "1                140.0            4.60  23.9  ...            1.0   102.0   \n",
              "2                140.6            4.72  23.9  ...            1.0   102.0   \n",
              "3                141.0            4.80  23.9  ...            1.0   102.0   \n",
              "4                141.0            4.80  23.9  ...            1.0   102.0   \n",
              "...                ...             ...   ...  ...            ...     ...   \n",
              "43841            136.0            3.30   NaN  ...            NaN     NaN   \n",
              "43842              NaN             NaN   NaN  ...            NaN     NaN   \n",
              "43843              NaN             NaN   NaN  ...            NaN     NaN   \n",
              "43844              NaN             NaN   NaN  ...            NaN     NaN   \n",
              "43845              NaN             NaN   NaN  ...            NaN     NaN   \n",
              "\n",
              "item   Kalium  Act.HCO3 (bloed)  Na (onv.ISE) (bloed)  K (onv.ISE) (bloed)  \\\n",
              "0         3.8         17.779999                 133.4                4.160   \n",
              "1         3.8         14.580000                 134.8                4.600   \n",
              "2         3.8         17.200000                 134.6                4.560   \n",
              "3         3.8         15.700000                 133.0                4.775   \n",
              "4         3.8         18.820001                 134.0                4.520   \n",
              "...       ...               ...                   ...                  ...   \n",
              "43841     NaN         30.400001                 133.0                3.600   \n",
              "43842     NaN         30.600000                 133.0                3.600   \n",
              "43843     NaN         30.600000                 133.0                3.600   \n",
              "43844     NaN         30.200001                 133.0                3.600   \n",
              "43845     NaN         30.200001                 133.0                3.600   \n",
              "\n",
              "item   Cl (onv.ISE) (bloed)  Niet invasieve bloeddruk gemiddeld  \\\n",
              "0                     114.0                                70.0   \n",
              "1                     114.0                                70.0   \n",
              "2                     114.0                                70.0   \n",
              "3                     114.0                                70.0   \n",
              "4                     114.0                                70.0   \n",
              "...                     ...                                 ...   \n",
              "43841                   NaN                                 NaN   \n",
              "43842                   NaN                                 NaN   \n",
              "43843                   NaN                                 NaN   \n",
              "43844                   NaN                                 NaN   \n",
              "43845                   NaN                                 NaN   \n",
              "\n",
              "item   ABP gemiddeld II  ABP gemiddeld  \n",
              "0                  61.0      64.000000  \n",
              "1                  61.0      72.400000  \n",
              "2                  61.0      71.200000  \n",
              "3                  61.0      66.750000  \n",
              "4                  61.0      63.800000  \n",
              "...                 ...            ...  \n",
              "43841               NaN      78.500000  \n",
              "43842               NaN      80.000000  \n",
              "43843               NaN      78.333333  \n",
              "43844               NaN      79.500000  \n",
              "43845               NaN      79.333333  \n",
              "\n",
              "[43846 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6ceb223-aa52-46e7-b1c3-00884f4cfcfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>item</th>\n",
              "      <th>admissionid</th>\n",
              "      <th>time</th>\n",
              "      <th>Urine</th>\n",
              "      <th>Kreatinine</th>\n",
              "      <th>Kreatinine (bloed)</th>\n",
              "      <th>KREAT enzym. (bloed)</th>\n",
              "      <th>Chloor (bloed)</th>\n",
              "      <th>Natrium (bloed)</th>\n",
              "      <th>Kalium (bloed)</th>\n",
              "      <th>HCO3</th>\n",
              "      <th>...</th>\n",
              "      <th>Chloor Astrup</th>\n",
              "      <th>Chloor</th>\n",
              "      <th>Kalium</th>\n",
              "      <th>Act.HCO3 (bloed)</th>\n",
              "      <th>Na (onv.ISE) (bloed)</th>\n",
              "      <th>K (onv.ISE) (bloed)</th>\n",
              "      <th>Cl (onv.ISE) (bloed)</th>\n",
              "      <th>Niet invasieve bloeddruk gemiddeld</th>\n",
              "      <th>ABP gemiddeld II</th>\n",
              "      <th>ABP gemiddeld</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>1970-01-01 00:00:00</td>\n",
              "      <td>10.666667</td>\n",
              "      <td>439.0</td>\n",
              "      <td>342.2</td>\n",
              "      <td>331.0</td>\n",
              "      <td>107.20</td>\n",
              "      <td>138.4</td>\n",
              "      <td>4.32</td>\n",
              "      <td>23.9</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>17.779999</td>\n",
              "      <td>133.4</td>\n",
              "      <td>4.160</td>\n",
              "      <td>114.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>64.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>1970-01-01 04:00:00</td>\n",
              "      <td>10.666667</td>\n",
              "      <td>439.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>108.40</td>\n",
              "      <td>140.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>23.9</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>14.580000</td>\n",
              "      <td>134.8</td>\n",
              "      <td>4.600</td>\n",
              "      <td>114.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>72.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>1970-01-01 08:00:00</td>\n",
              "      <td>10.666667</td>\n",
              "      <td>439.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>107.00</td>\n",
              "      <td>140.6</td>\n",
              "      <td>4.72</td>\n",
              "      <td>23.9</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>134.6</td>\n",
              "      <td>4.560</td>\n",
              "      <td>114.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>71.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>1970-01-01 12:00:00</td>\n",
              "      <td>9.633333</td>\n",
              "      <td>439.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>108.25</td>\n",
              "      <td>141.0</td>\n",
              "      <td>4.80</td>\n",
              "      <td>23.9</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>133.0</td>\n",
              "      <td>4.775</td>\n",
              "      <td>114.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>66.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1970-01-01 16:00:00</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>439.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>105.60</td>\n",
              "      <td>141.0</td>\n",
              "      <td>4.80</td>\n",
              "      <td>23.9</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>18.820001</td>\n",
              "      <td>134.0</td>\n",
              "      <td>4.520</td>\n",
              "      <td>114.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>63.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43841</th>\n",
              "      <td>23545</td>\n",
              "      <td>1970-01-03 04:00:00</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136.0</td>\n",
              "      <td>3.30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.400001</td>\n",
              "      <td>133.0</td>\n",
              "      <td>3.600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>78.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43842</th>\n",
              "      <td>23545</td>\n",
              "      <td>1970-01-03 08:00:00</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.600000</td>\n",
              "      <td>133.0</td>\n",
              "      <td>3.600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43843</th>\n",
              "      <td>23545</td>\n",
              "      <td>1970-01-03 12:00:00</td>\n",
              "      <td>595.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.600000</td>\n",
              "      <td>133.0</td>\n",
              "      <td>3.600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>78.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43844</th>\n",
              "      <td>23545</td>\n",
              "      <td>1970-01-03 16:00:00</td>\n",
              "      <td>570.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.200001</td>\n",
              "      <td>133.0</td>\n",
              "      <td>3.600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43845</th>\n",
              "      <td>23545</td>\n",
              "      <td>1970-01-03 20:00:00</td>\n",
              "      <td>420.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.200001</td>\n",
              "      <td>133.0</td>\n",
              "      <td>3.600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43846 rows  23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6ceb223-aa52-46e7-b1c3-00884f4cfcfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6ceb223-aa52-46e7-b1c3-00884f4cfcfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6ceb223-aa52-46e7-b1c3-00884f4cfcfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Save Aggregated Dataframe on Drive"
      ],
      "metadata": {
        "id": "muHoNB95Ofum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated.to_csv('aggregated.csv')"
      ],
      "metadata": {
        "id": "8NYG5CrvOmq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Plot Statistics"
      ],
      "metadata": {
        "id": "9sF8r0eVlXk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot some stats, df with 1 row per patient for demographic stats\n",
        "state_stats = state.drop_duplicates(subset=['admissionid'], keep='first')"
      ],
      "metadata": {
        "id": "GlLzI0-GlJDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}