{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLREASONINGFORHEALTH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wObiuw_qeCNN"
      },
      "source": [
        "<img src=\"https://github.com/AmsterdamUMC/AmsterdamUMCdb/blob/master/courses/2021-11-vu-ml-reasoning/vu.jpg?raw=1\" alt=\"Logo\" width=128px/>\n",
        "\n",
        "<img src=\"https://github.com/AmsterdamUMC/AmsterdamUMCdb/blob/master/img/logo_amds.png?raw=1\" alt=\"Logo\" width=128px/>\n",
        "\n",
        "# Machine Learning and Reasoning for Health - Vrije Universiteit Amsterdam\n",
        "## AmsterdamUMCdb - Freely Accessible ICU Database\n",
        "\n",
        "AmsterdamUMCdb version 1.0.2 March 2020  \n",
        "Copyright &copy; 2003-2021 Amsterdam UMC - Amsterdam Medical Data Science"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "hQnpY5Kpm5rT"
      },
      "source": [
        "#sets the project id\n",
        "PROJECT_ID = \"gentle-bearing-330917\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB_NEmEZtLpg"
      },
      "source": [
        "## Access AmsterdamUMCdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0L2i-Nnp7_R",
        "outputId": "c9ed0cba-a31a-44ef-ba86-545b74b58929"
      },
      "source": [
        "import os\n",
        "from google.colab import auth\n",
        " \n",
        "#sets dateset\n",
        "DATASET_PROJECT_ID = 'amsterdamumcdb'\n",
        "DATASET_ID = 'version1_0_2'\n",
        "LOCATION = 'eu'\n",
        " \n",
        "#all libraries check this environment variable, so set it:\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        " \n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMNA-vBHPyHz"
      },
      "source": [
        "%load_ext google.colab.data_table"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC7nOYOCKFvQ"
      },
      "source": [
        "from google.cloud.bigquery import magics\n",
        "from google.cloud import bigquery\n",
        "\n",
        "#sets the default query job configuration\n",
        "def_config = bigquery.job.QueryJobConfig(default_dataset=DATASET_PROJECT_ID + \".\" + DATASET_ID)\n",
        "magics.context.default_query_job_config = def_config\n",
        "\n",
        "#sets client options job configuration\n",
        "client_options = {}\n",
        "client_options['location'] = LOCATION\n",
        "magics.context.bigquery_client_options = client_options"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alCUc9QYTGQT"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "#BigQuery requires a separate config to prevent the 'BadRequest: 400 Cannot explicitly modify anonymous table' error message\n",
        "job_config = bigquery.job.QueryJobConfig()\n",
        "\n",
        "#sets default client settings by re-using the previously defined config\n",
        "client = bigquery.Client(project=PROJECT_ID, location=LOCATION, default_query_job_config=def_config)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2SfaHSCTyWT"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "config_gbq = {'query': \n",
        "          {'defaultDataset': {\n",
        "              \"datasetId\": DATASET_ID, \n",
        "              \"projectId\": DATASET_PROJECT_ID\n",
        "              },\n",
        "           'Location': LOCATION}\n",
        "           }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kefpJwsNZ0sf",
        "outputId": "25e41574-acde-47a6-a369-ff5b7ff4f6e1"
      },
      "source": [
        "#get the amsterdamumcdb package from PiPy repository for use in Colab\n",
        "!pip install amsterdamumcdb\n",
        "import amsterdamumcdb as adb"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting amsterdamumcdb\n",
            "  Downloading amsterdamumcdb-0.1.3-py3-none-any.whl (199 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 30 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 40 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 122 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 133 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 153 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 163 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 174 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 184 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 194 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 199 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from amsterdamumcdb) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from amsterdamumcdb) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->amsterdamumcdb) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->amsterdamumcdb) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->amsterdamumcdb) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->amsterdamumcdb) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->amsterdamumcdb) (1.15.0)\n",
            "Installing collected packages: amsterdamumcdb\n",
            "Successfully installed amsterdamumcdb-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va9OrTrgeH-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d394255-2fe0-41b5-b7f8-44b852d10287"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('/content/drive/MyDrive/MLRFH')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tfvAZ7664nm"
      },
      "source": [
        "## Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pwJjrIm7ttO"
      },
      "source": [
        "# data = pd.read_gbq(\n",
        "#     '''\n",
        "#     WITH sepsis AS (\n",
        "#       SELECT \n",
        "#     l.admissionid\n",
        "# FROM listitems_validated l\n",
        "# LEFT JOIN admissions a ON\n",
        "#         l.admissionid = a.admissionid\n",
        "#  WHERE \n",
        "#     (\n",
        "#         l.itemid = 15808  --Opname Sepsis\n",
        "#         AND (l.itemid = 16675  --DMC_Opname Sepsis\n",
        "#         )\n",
        "#         AND (l.value = 'Ja'))\n",
        "# GROUP BY l.admissionid\n",
        "# ),\n",
        "# action AS (    SELECT\n",
        "#         d.admissionid\n",
        "#     FROM drugitems d\n",
        "#     LEFT JOIN admissions a ON\n",
        "#         d.admissionid = a.admissionid\n",
        "#     WHERE \n",
        "#         d.ordercategoryid = 55 \n",
        "#         AND d.itemid IN (\n",
        "#             7229, -- Noradrenaline (Norepinefrine)\n",
        "#             7291  -- Crystalloid (fluid)\n",
        "#         )\n",
        "#         GROUP BY d.admissionid\n",
        "#     ),\n",
        "#   state as (\n",
        "#     SELECT n.admissionid,\n",
        "#     FROM numericitems_validated n\n",
        "#     LEFT JOIN admissions a ON\n",
        "#         n.admissionid = a.admissionid\n",
        "#     WHERE n.itemid IN (\n",
        "#     9941,  --Kreatinine (blood)\n",
        "#     8794,  --UrineCAD\n",
        "#     6642,  --ABP Mean Blood Pressure\n",
        "#     9924,  --Natrium in blood\n",
        "#     9927,  --Kalium in blood\n",
        "#     6836  --Kreatinine\n",
        "#     , 8796  --UrineSupraPubis\n",
        "#     , 8798 --UrineSpontaan\n",
        "#     , 8800 --UrineIncontinentie\n",
        "#     , 8803 --UrineUP\n",
        "#     , 10743 --Nefrodrain li Uit\n",
        "#     , 10745 --Nefrodrain re Uit\n",
        "#         ) \n",
        "#       GROUP BY n.admissionid\n",
        "#   )\n",
        "#   SELECT \n",
        "#     n.admissionid,\n",
        "#     n.itemid,\n",
        "#     n.item,\n",
        "#     n.value,\n",
        "#     n.registeredby,\n",
        "#     n.measuredat,\n",
        "#     (n.measuredat - a.admittedat) AS time,\n",
        "#     a.weightgroup,\n",
        "#     a.heightgroup,\n",
        "#     a.gender,\n",
        "#     a.agegroup,\n",
        "#     FROM numericitems_validated n\n",
        "#     LEFT JOIN admissions a ON\n",
        "#     n.admissionid = a.admissionid\n",
        "#     LEFT JOIN sepsis s ON\n",
        "#     n.admissionid = s.admissionid\n",
        "#     LEFT JOIN action v ON\n",
        "#     n.admissionid = v.admissionid\n",
        "#     LEFT JOIN state r ON \n",
        "#     n.admissionid = r.admissionid\n",
        "#     WHERE n.itemid IN (\n",
        "#     9941,  --Kreatinine (blood)\n",
        "#     8794,  --UrineCAD\n",
        "#     6642,  --ABP Mean Blood Pressure\n",
        "#     9924,  --Natrium in blood\n",
        "#     9927,  --Kalium in blood\n",
        "#     6836  --Kreatinine\n",
        "#     , 8796  --UrineSupraPubis\n",
        "#     , 8798 --UrineSpontaan\n",
        "#     , 8800 --UrineIncontinentie\n",
        "#     , 8803 --UrineUP\n",
        "#     , 10743 --Nefrodrain li Uit\n",
        "#     , 10745 --Nefrodrain re Uit\n",
        "#     ) \n",
        "#     '''\n",
        "#     , configuration=config_gbq)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH_7Z1kLanXq"
      },
      "source": [
        "# action_space = pd.read_gbq(\n",
        "#     '''\n",
        "#     WITH MV AS (\n",
        "#       SELECT \n",
        "#     l.admissionid,\n",
        "# FROM listitems_validated l\n",
        "# LEFT JOIN admissions a ON\n",
        "#         l.admissionid = a.admissionid\n",
        "#  WHERE \n",
        "#     (\n",
        "#         l.itemid = 15808  --Opname Sepsis\n",
        "#         AND (l.itemid = 16675  --DMC_Opname Sepsis\n",
        "#         )\n",
        "#         AND (l.value = 'Ja'))\n",
        "#       GROUP BY l.admissionid\n",
        "# ),\n",
        "# VASOP AS (    SELECT\n",
        "#     d.admissionid\n",
        "#     FROM drugitems d\n",
        "#     LEFT JOIN listitems_validated l ON\n",
        "#         d.admissionid = l.admissionid\n",
        "#     WHERE (\n",
        "#         d.ordercategoryid = 55 -- continuous i.v. perfusor\n",
        "#         AND d.itemid IN (\n",
        "#             7229, -- Noradrenaline (Norepinefrine)\n",
        "#             7291  -- Crystalloid (fluid)\n",
        "#         ) AND l.itemid  IN ( \n",
        "#           15808,  --Opname Sepsis\n",
        "#           16675  --DMC_Opname Sepsis\n",
        "#         )\n",
        "#         AND (l.value = 'Ja')\n",
        "#         ) \n",
        "#         GROUP BY admissionid\n",
        "#     ),\n",
        "#   RRT as (\n",
        "#     SELECT n.admissionid,\n",
        "#     CASE\n",
        "#         WHEN COUNT(*) > 0 THEN TRUE\n",
        "#         ELSE FALSE\n",
        "#     END AS renal_replacement_bool,\n",
        "#     FROM numericitems_validated n\n",
        "#     LEFT JOIN admissions a ON\n",
        "#         n.admissionid = a.admissionid\n",
        "#     WHERE n.itemid IN (\n",
        "#             10736, --Bloed-flow\n",
        "#             12460, --Bloedflow\n",
        "#             14850 --MFT_Bloedflow (ingesteld): Fresenius multiFiltrate blood flow\n",
        "#         ) \n",
        "#       GROUP BY n.admissionid\n",
        "# ),\n",
        "# baseline AS (\n",
        "#       SELECT n.admissionid,\n",
        "#       MIN(n.value) AS baseline_creatinine\n",
        "#       FROM numericitems_validated n\n",
        "#       LEFT JOIN admissions a ON\n",
        "#         n.admissionid = a.admissionid\n",
        "#       WHERE itemid IN (\n",
        "#         6836, --Kreatinine µmol/l (erroneously documented as µmol)\n",
        "#         9941, --Kreatinine (bloed) µmol/l\n",
        "#         14216 --KREAT enzym. (bloed) µmol/l\n",
        "#       )\n",
        "#       GROUP BY n.admissionid\n",
        "#     )\n",
        "#   SELECT \n",
        "#     dr.admissionid,\n",
        "#     dr.itemid,\n",
        "#     dr.item,\n",
        "#     dr.start, \n",
        "#     dr.stop,\n",
        "#     dr.administered,\n",
        "#     a.weightgroup,\n",
        "#     a.heightgroup,\n",
        "#     a.gender,\n",
        "#     a.agegroup\n",
        "#     FROM drugitems dr\n",
        "#     LEFT JOIN admissions a ON\n",
        "#     dr.admissionid = a.admissionid\n",
        "#     LEFT JOIN MV m ON\n",
        "#     dr.admissionid = m.admissionid\n",
        "#     LEFT JOIN VASOP v ON\n",
        "#     dr.admissionid = v.admissionid\n",
        "#     LEFT JOIN RRT r ON \n",
        "#     dr.admissionid = r.admissionid\n",
        "#     LEFT JOIN baseline b ON\n",
        "#     dr.admissionid = b.admissionid\n",
        "#     WHERE dr.itemid IN (\n",
        "#         7229, -- Noradrenaline (Norepinefrine)\n",
        "#         7291  -- Crystalloid (fluid)\n",
        "#     )\n",
        "#     '''\n",
        "#     , configuration=config_gbq)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utpvujOTb3ZN"
      },
      "source": [
        "# action_space.to_csv('action_space.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY4kdHv969IM"
      },
      "source": [
        "## Saving/Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-JP2h0hI4sT"
      },
      "source": [
        "space = pd.read_csv('space_correct_demo7.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgAGD0oq7D1K"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd0Ldmox6F8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b8db9fe5-ae00-4f82-efe2-3d333a3bba22"
      },
      "source": [
        "urine = space['UrineCAD']\n",
        "adb.outliers_histogram(data=urine).show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJZ4cLJI8mjm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "0aaa388e-8b02-4e41-bab5-1b5a87c99b68"
      },
      "source": [
        "kreat = space['Kreatinine (bloed)']\n",
        "adb.outliers_histogram(data=kreat).show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj-kDKhn82LC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "47eae2b3-f17e-4e98-ae22-9dca9cdaf0fb"
      },
      "source": [
        "blood = space['ABP gemiddeld']\n",
        "adb.outliers_histogram(data=blood).show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWRABhFM9Cfx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d8df5727-cc9c-4e61-a1b0-a640585647bb"
      },
      "source": [
        "natrium = space['Natrium (bloed)']\n",
        "adb.outliers_histogram(data=natrium, ).show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYfZWVLs9lvF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "bc0e9da5-3741-4fe5-9977-6f356b4e23ef"
      },
      "source": [
        "kalium = space['Kalium (bloed)']\n",
        "adb.outliers_histogram(data=kalium).show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmhfp9cXJpxs"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.colors as cl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as md\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.cm as cm\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "import itertools\n",
        "from scipy.optimize import curve_fit\n",
        "import re\n",
        "import math\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import dateutil\n",
        "\n",
        "class VisualizeDataset:\n",
        "\n",
        "    point_displays = ['+', 'x'] #'*', 'd', 'o', 's', '<', '>']\n",
        "    line_displays = ['-'] #, '--', ':', '-.']\n",
        "    colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
        "\n",
        "    # Set some initial attributes to define and create a save location for the images.\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # Plot the dataset, here columns can specify a specific attribute, but also a generic name that occurs\n",
        "    # among multiple attributes (e.g. label which occurs as labelWalking, etc). In such a case they are plotted\n",
        "    # in the same graph. The display should express whether points or a line should be plotted.\n",
        "    # Match can be 'exact' or 'like'. Display can be 'points' or 'line'.\n",
        "    def plot_dataset(self, data_table, columns, match='like', display='line'):\n",
        "        names = list(data_table.columns)\n",
        "\n",
        "        # Create subplots if more columns are specified.\n",
        "        if len(columns) > 1:\n",
        "            f, xar = plt.subplots(len(columns), sharex=True, sharey=False)\n",
        "        else:\n",
        "            f, xar = plt.subplots()\n",
        "            xar = [xar]\n",
        "\n",
        "        f.subplots_adjust(hspace=0.4)\n",
        "\n",
        "        xfmt = md.DateFormatter('%H:%M')\n",
        "\n",
        "        # Pass through the columns specified.\n",
        "        for i in range(0, len(columns)):\n",
        "            xar[i].xaxis.set_major_formatter(xfmt)\n",
        "            xar[i].set_prop_cycle(color=['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
        "            # if a column match is specified as 'exact', select the column name(s) with an exact match.\n",
        "            # If it's specified as 'like', select columns containing the name.\n",
        "\n",
        "            # We can match exact (i.e. a columns name is an exact name of a columns or 'like' for\n",
        "            # which we need to find columns names in the dataset that contain the name.\n",
        "            if match[i] == 'exact':\n",
        "                relevant_cols = [columns[i]]\n",
        "            elif match[i] == 'like':\n",
        "                relevant_cols = [name for name in names if columns[i] == name[0:len(columns[i])]]\n",
        "            else:\n",
        "                raise ValueError(\"Match should be 'exact' or 'like' for \" + str(i) + \".\")\n",
        "\n",
        "            max_values = []\n",
        "            min_values = []\n",
        "\n",
        "\n",
        "\n",
        "            # Pass through the relevant columns.\n",
        "            for j in range(0, len(relevant_cols)):\n",
        "                # Create a mask to ignore the NaN and Inf values when plotting:\n",
        "                mask = data_table[relevant_cols[j]].replace([np.inf, -np.inf], np.nan).notnull()\n",
        "                max_values.append(data_table[relevant_cols[j]][mask].max())\n",
        "                min_values.append(data_table[relevant_cols[j]][mask].min())\n",
        "\n",
        "                # Display point, or as a line\n",
        "                if display[i] == 'points':\n",
        "                    xar[i].plot(data_table.index[mask], data_table[relevant_cols[j]][mask],\n",
        "                                self.point_displays[j%len(self.point_displays)])\n",
        "                else:\n",
        "                    xar[i].plot(data_table.index[mask], data_table[relevant_cols[j]][mask],\n",
        "                                self.line_displays[j%len(self.line_displays)])\n",
        "\n",
        "            xar[i].tick_params(axis='y', labelsize=10)\n",
        "            xar[i].legend(relevant_cols, fontsize='xx-small', numpoints=1, loc='upper center',\n",
        "                          bbox_to_anchor=(0.5, 1.3), ncol=len(relevant_cols), fancybox=True, shadow=True)\n",
        "\n",
        "            xar[i].set_ylim([min(min_values) - 0.1*(max(max_values) - min(min_values)),\n",
        "                             max(max_values) + 0.1*(max(max_values) - min(min_values))])\n",
        "\n",
        "        # Make sure we get a nice figure with only a single x-axis and labels there.\n",
        "        plt.setp([a.get_xticklabels() for a in f.axes[:-1]], visible=False)\n",
        "        plt.xlabel('time')\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_xy(self, x, y, method='plot', xlabel=None, ylabel=None, xlim=None, ylim=None, names=None,\n",
        "                line_styles=None, loc=None, title=None):\n",
        "        for input in x, y:\n",
        "            if not hasattr(input[0], '__iter__'):\n",
        "                raise TypeError('x/y should be given as a list of lists of coordinates')\n",
        "\n",
        "        plot_method = getattr(plt, method)\n",
        "        for i, (x_line, y_line) in enumerate(zip(x, y)):\n",
        "\n",
        "            plot_method(x_line, y_line, line_styles[i]) if line_styles is not None else plt.plot(x_line, y_line)\n",
        "\n",
        "            if xlabel is not None: plt.xlabel(xlabel)\n",
        "            if ylabel is not None: plt.ylabel(ylabel)\n",
        "            if xlim is not None: plt.xlim(xlim)\n",
        "            if ylim is not None: plt.ylim(ylim)\n",
        "            if title is not None: plt.title(title)\n",
        "            if names is not None: plt.legend(names)\n",
        "\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_dataset_boxplot(self, dataset, cols):\n",
        "        plt.Figure(); dataset[cols].plot.box()\n",
        "        plt.ylim([-30,30])\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # This function plots the real and imaginary amplitudes of the frequencies found in the Fourier transformation.\n",
        "    def plot_fourier_amplitudes(self, freq, ampl_real, ampl_imag):\n",
        "        plt.xlabel('Freq(Hz)')\n",
        "        plt.ylabel('amplitude')\n",
        "        # Plot the real values as a '+' and imaginary in the same way (though with a different color).\n",
        "        plt.plot(freq, ampl_real, '+', freq, ampl_imag,'+')\n",
        "        plt.legend(['real', 'imaginary'], numpoints=1)\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # Plot outliers in case of a binary outlier score. Here, the col specifies the real data\n",
        "    # column and outlier_col the columns with a binary value (outlier or not)\n",
        "    def plot_binary_outliers(self, data_table, col, outlier_col):\n",
        "        data_table.loc[:,:] = data_table.dropna(axis=0, subset=[col, outlier_col])\n",
        "        data_table.loc[:,outlier_col] = data_table[outlier_col].astype('bool')\n",
        "        f, xar = plt.subplots()\n",
        "        xfmt = md.DateFormatter('%H:%M')\n",
        "        xar.xaxis.set_major_formatter(xfmt)\n",
        "        plt.xlabel('time')\n",
        "        plt.ylabel('value')\n",
        "        # Plot data points that are outliers in red, and non outliers in blue.\n",
        "        xar.plot(data_table.index[data_table[outlier_col]], data_table[col][data_table[outlier_col]], 'r+')\n",
        "        xar.plot(data_table.index[~data_table[outlier_col]], data_table[col][~data_table[outlier_col]], 'b+')\n",
        "        plt.legend(['outlier ' + col, 'no_outlier_' + col], numpoints=1, fontsize='xx-small', loc='upper center',  ncol=2, fancybox=True, shadow=True)\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # Plot values that have been imputed using one of our imputation approaches. Here, values expresses the\n",
        "    # 1 to n datasets that have resulted from value imputation.\n",
        "    def plot_imputed_values(self, data_table, names, col, *values):\n",
        "\n",
        "        xfmt = md.DateFormatter('%H:%M')\n",
        "\n",
        "        # Create proper subplots.\n",
        "        if len(values) > 0:\n",
        "            f, xar = plt.subplots(len(values) + 1, sharex=True, sharey=False)\n",
        "        else:\n",
        "            f, xar = plt.subplots()\n",
        "            xar = [xar]\n",
        "\n",
        "        f.subplots_adjust(hspace=0.4)\n",
        "\n",
        "        # plot the regular dataset.\n",
        "\n",
        "        xar[0].xaxis.set_major_formatter(xfmt)\n",
        "        xar[0].plot(data_table.index[data_table[col].notnull()], data_table[col][data_table[col].notnull()], 'b+', markersize='2')\n",
        "        xar[0].legend([names[0]], fontsize='small', numpoints=1, loc='upper center',  bbox_to_anchor=(0.5, 1.3), ncol=1, fancybox=True, shadow=True)\n",
        "\n",
        "        # and plot the others that have resulted from imputation.\n",
        "        for i in range(1, len(values)+1):\n",
        "            xar[i].xaxis.set_major_formatter(xfmt)\n",
        "            xar[i].plot(data_table.index, values[i-1], 'b+', markersize='2')\n",
        "            xar[i].legend([names[i]], fontsize='small', numpoints=1, loc='upper center',  bbox_to_anchor=(0.5, 1.3), ncol=1, fancybox=True, shadow=True)\n",
        "\n",
        "        # Diplay is nicely in subplots.\n",
        "        plt.setp([a.get_xticklabels() for a in f.axes[:-1]], visible=False)\n",
        "        plt.xlabel('time')\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # This function plots clusters that result from the application of a clustering algorithm\n",
        "    # and also shows the class label of points. Clusters are displayed via colors, classes\n",
        "    # by means of different types of points. We assume that three data columns are clustered\n",
        "    # that do not include the label. We assume the labels to be represented by 1 or more binary\n",
        "    # columns.\n",
        "    def plot_clusters_3d(self, data_table, data_cols, cluster_col, label_cols):\n",
        "\n",
        "        color_index = 0\n",
        "        point_displays = ['+', 'x', '*', 'd', 'o', 's', '<', '>']\n",
        "\n",
        "        # Determine the number of clusters:\n",
        "        clusters = data_table[cluster_col].unique()\n",
        "        labels = []\n",
        "\n",
        "        # Get the possible labels, assuming 1 or more label columns with binary values.\n",
        "        for i in range(0, len(label_cols)):\n",
        "            labels.extend([name for name in list(data_table.columns) if label_cols[i] == name[0:len(label_cols[i])]])\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        handles = []\n",
        "\n",
        "        # Plot clusters individually with a certain color.\n",
        "        for cluster in clusters:\n",
        "            marker_index = 0\n",
        "            # And make sure the points of a label receive the right marker type.\n",
        "            for label in labels:\n",
        "                rows = data_table.loc[(data_table[cluster_col] == cluster) & (data_table[label] > 0)]\n",
        "                # Now we come to the assumption that there are three data_cols specified:\n",
        "                if not len(data_cols) == 3:\n",
        "                    return\n",
        "                plot_color = self.colors[color_index%len(self.colors)]\n",
        "                plot_marker = point_displays[marker_index%len(point_displays)]\n",
        "                pt = ax.scatter(rows[data_cols[0]], rows[data_cols[1]], rows[data_cols[2]], c=plot_color, marker=plot_marker)\n",
        "                if color_index == 0:\n",
        "                    handles.append(pt)\n",
        "                ax.set_xlabel(data_cols[0])\n",
        "                ax.set_ylabel(data_cols[1])\n",
        "                ax.set_zlabel(data_cols[2])\n",
        "                marker_index += 1\n",
        "            color_index += 1\n",
        "\n",
        "        plt.legend(handles, labels, fontsize='xx-small', numpoints=1)\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # This function plots the silhouettes of the different clusters that have been identified. It plots the\n",
        "    # silhouette of the individual datapoints per cluster to allow studying the clusters internally as well.\n",
        "    # For this, a column expressing the silhouette for each datapoint is assumed.\n",
        "    def plot_silhouette(self, data_table, cluster_col, silhouette_col):\n",
        "        # Taken from the examples of scikit learn\n",
        "        #(http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)\n",
        "\n",
        "        clusters = data_table[cluster_col].unique()\n",
        "\n",
        "        fig, ax1 = plt.subplots(1, 1)\n",
        "        ax1.set_xlim([-0.1, 1])\n",
        "        #ax1.set_ylim([0, len(data_table.index) + (len(clusters) + 1) * 10])\n",
        "        y_lower = 10\n",
        "        for i in range(0, len(clusters)):\n",
        "            # Aggregate the silhouette scores for samples belonging to\n",
        "            # cluster i, and sort them\n",
        "            rows = data_table.mask(data_table[cluster_col] == clusters[i])\n",
        "            ith_cluster_silhouette_values = np.array(rows[silhouette_col])\n",
        "            ith_cluster_silhouette_values.sort()\n",
        "\n",
        "            size_cluster_i = len(rows.index)\n",
        "            y_upper = y_lower + size_cluster_i\n",
        "\n",
        "            color = plt.get_cmap('Spectral')(float(i) / len(clusters))\n",
        "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "            # Label the silhouette plots with their cluster numbers at the middle\n",
        "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "            # Compute the new y_lower for next plot\n",
        "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "        ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "        # The vertical line for average silhouette score of all the values\n",
        "        ax1.axvline(x=data_table[silhouette_col].mean(), color=\"red\", linestyle=\"--\")\n",
        "\n",
        "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # Plot a dendorgram for hierarchical clustering. It assumes that the linkage as\n",
        "    # used in sk learn is passed as an argument as well.\n",
        "    def plot_dendrogram(self, dataset, linkage):\n",
        "        sys.setrecursionlimit(40000)\n",
        "        plt.title('Hierarchical Clustering Dendrogram')\n",
        "        plt.xlabel('time points')\n",
        "        plt.ylabel('distance')\n",
        "        times = dataset.index.strftime('%H:%M:%S')\n",
        "        #dendrogram(linkage,truncate_mode='lastp',p=10, show_leaf_counts=True, leaf_rotation=90.,leaf_font_size=12.,show_contracted=True, labels=times)\n",
        "        dendrogram(linkage,truncate_mode='lastp',p=16, show_leaf_counts=True, leaf_rotation=45.,leaf_font_size=8.,show_contracted=True, labels=times)\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # Plot the confusion matrix that has been derived in the evaluation metrics. Classes expresses the labels\n",
        "    # for the matrix. We can normalize or show the raw counts. Of course this applies to classification problems.\n",
        "    def plot_confusion_matrix(self, cm, classes, normalize=False):\n",
        "        # Taken from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "        # Select the colormap.\n",
        "        cmap=plt.cm.Blues\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title('confusion matrix')\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(classes))\n",
        "        plt.xticks(tick_marks, classes, rotation=45)\n",
        "        plt.yticks(tick_marks, classes)\n",
        "\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # This function plots the predictions or an algorithms (both for the training and test set) versus the real values for\n",
        "    # a regression problem. It assumes only a single value to be predicted over a number of cases. The variables identified\n",
        "    # with reg_ are the predictions.\n",
        "    def plot_numerical_prediction_versus_real(self, train_time, train_y, regr_train_y, test_time, test_y, regr_test_y, label):\n",
        "        self.legends = {}\n",
        "\n",
        "        # Plot the values, training set cases in blue, test set in red.\n",
        "        f, xar = plt.subplots(1, 1)\n",
        "\n",
        "        xfmt = md.DateFormatter('%H:%M')\n",
        "        xar.xaxis.set_major_formatter(xfmt)\n",
        "        xar.set_prop_cycle(color=['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
        "        plt.plot(train_time, train_y, '-', linewidth=0.5)\n",
        "        plt.plot(train_time, regr_train_y, '--', linewidth=0.5)\n",
        "\n",
        "        plt.plot(test_time, test_y, '-', linewidth=0.5)\n",
        "        plt.plot(test_time, regr_test_y, '--', linewidth=0.5)\n",
        "\n",
        "        plt.legend(['real values training', 'predicted values training', 'real values test', 'predicted values test'], loc=4)\n",
        "\n",
        "\n",
        "        # And create some fancy stuff in the figure to label the training and test set a bit clearer.\n",
        "        max_y_value = max(max(train_y.tolist()), max(regr_train_y.tolist()), max(test_y.tolist()), max(regr_test_y.tolist()))\n",
        "        min_y_value = min(min(train_y.tolist()), min(regr_train_y.tolist()), min(test_y.tolist()), min(regr_test_y.tolist()))\n",
        "        range = max_y_value - min_y_value\n",
        "        y_coord_labels = max(max(train_y.tolist()), max(regr_train_y.tolist()), max(test_y.tolist()), max(regr_test_y.tolist()))+(0.01*range)\n",
        "\n",
        "\n",
        "        plt.title('Performance of model for ' + str(label))\n",
        "        plt.ylabel(label)\n",
        "        plt.xlabel('time')\n",
        "        plt.annotate('', xy=(train_time[0],y_coord_labels), xycoords='data', xytext=(train_time[-1], y_coord_labels), textcoords='data', arrowprops={'arrowstyle': '<->'})\n",
        "        plt.annotate('training set', xy=(train_time[int(float(len(train_time))/2)], y_coord_labels*1.02), color='blue', xycoords='data', ha='center')\n",
        "        plt.annotate('', xy=(test_time[0], y_coord_labels), xycoords='data', xytext=(test_time[-1], y_coord_labels), textcoords='data', arrowprops={'arrowstyle': '<->'})\n",
        "        plt.annotate('test set', xy=(test_time[int(float(len(test_time))/2)], y_coord_labels*1.02), color='red', xycoords='data', ha='center')\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # Plot the Pareto front for multi objective optimization problems (for the dynamical systems stuff). We consider the\n",
        "    # raw output of the MO dynamical systems approach, which includes rows with the fitness and predictions for the training\n",
        "    # and test set. We select the fitness and plot them in a graph. Note that the plot only considers the first two dimensions.\n",
        "    def plot_pareto_front(self, dynsys_output):\n",
        "        fit_1_train = []\n",
        "        fit_2_train = []\n",
        "        fit_1_test = []\n",
        "        fit_2_test = []\n",
        "        for row in dynsys_output:\n",
        "            fit_1_train.append(row[1][0])\n",
        "            fit_2_train.append(row[1][1])\n",
        "\n",
        "        plt.scatter(fit_1_train, fit_2_train, color='r')\n",
        "        plt.xlabel('mse on ' + str(dynsys_output[0][0].columns[0]))\n",
        "        plt.ylabel('mse on ' + str(dynsys_output[0][0].columns[1]))\n",
        "        #plt.savefig('{0} Example ({1}).pdf'.format(ea.__class__.__name__, problem.__class__.__name__), format='pdf')\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    # Plot a prediction for a regression model in case it concerns a multi-objective dynamical systems model. Here, we plot\n",
        "    # the individual specified. Again, the complete output of the MO approach is used as argument.\n",
        "    def plot_numerical_prediction_versus_real_dynsys_mo(self, train_time, train_y, test_time, test_y, dynsys_output, individual, label):\n",
        "        regr_train_y = dynsys_output[individual][0][label]\n",
        "        regr_test_y = dynsys_output[individual][2][label]\n",
        "        train_y = train_y[label]\n",
        "        test_y = test_y[label]\n",
        "        self.plot_numerical_prediction_versus_real(train_time, train_y, regr_train_y, test_time, test_y, regr_test_y, label)\n",
        "\n",
        "    # Visualizes the performance of different algorithms over different feature sets. Assumes the scores to contain\n",
        "    # a score on the training set followed by an sd, and the same for the test set.\n",
        "    def plot_performances(self, algs, feature_subset_names, scores_over_all_algs, ylim, std_mult, y_name):\n",
        "\n",
        "        width = float(1)/(len(feature_subset_names)+1)\n",
        "        ind = np.arange(len(algs))\n",
        "        for i in range(0, len(feature_subset_names)):\n",
        "            means = []\n",
        "            std = []\n",
        "            for j in range(0, len(algs)):\n",
        "                means.append(scores_over_all_algs[i][j][2])\n",
        "                std.append(std_mult * scores_over_all_algs[i][j][3])\n",
        "            plt.errorbar(ind + i * width, means, yerr=std, fmt=self.colors[i%len(self.colors)] + 'o', markersize='3')\n",
        "        plt.ylabel(y_name)\n",
        "        plt.xticks(ind+(float(len(feature_subset_names))/2)*width, algs)\n",
        "        plt.legend(feature_subset_names, loc=4, numpoints=1)\n",
        "        if not ylim is None:\n",
        "            plt.ylim(ylim)\n",
        "        self.save(plt)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_performances_classification(self, algs, feature_subset_names, scores_over_all_algs):\n",
        "        self.plot_performances(algs, feature_subset_names, scores_over_all_algs, [0.70, 1.0], 2, 'Accuracy')\n",
        "\n",
        "    def plot_performances_regression(self, algs, feature_subset_names, scores_over_all_algs):\n",
        "        self.plot_performances(algs, feature_subset_names, scores_over_all_algs, None, 1, 'Mean Squared Error')"
      ],
      "metadata": {
        "id": "p8a5_NwfWXcN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################\n",
        "#                                                            #\n",
        "#    Mark Hoogendoorn and Burkhardt Funk (2017)              #\n",
        "#    Machine Learning for the Quantified Self                #\n",
        "#    Springer                                                #\n",
        "#    Chapter 5                                               #\n",
        "#                                                            #\n",
        "##############################################################\n",
        "\n",
        "import math\n",
        "import numbers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "from scipy import stats\n",
        "import sys\n",
        "from sklearn.neighbors import DistanceMetric\n",
        "import sklearn\n",
        "\n",
        "\n",
        "\n",
        "# Class defining the distance metrics that are not available as standard ones....\n",
        "class InstanceDistanceMetrics:\n",
        "\n",
        "    # S for gowers distance\n",
        "    def s(self, val1, val2, range):\n",
        "        # If we compare numbers we look at the difference and normalize.\n",
        "        if isinstance(val1, numbers.Number) and isinstance(val1, numbers.Number):\n",
        "            return 1 - (float(abs(val1-val2))/range)\n",
        "        # If we compare something else, we just look at whether they are equal.\n",
        "        else:\n",
        "            if val1 == val2:\n",
        "                return 1\n",
        "            else:\n",
        "                return 0\n",
        "\n",
        "    # Delta for gowers distance.\n",
        "    def delta(self, val1, val2):\n",
        "        # Check whether both values are known (i.e. nan), if so the delta is 1, 0 otherwise.\n",
        "        if (not np.isnan(val1)) and (not np.isnan(val2)):\n",
        "            return 1\n",
        "        return 0\n",
        "\n",
        "    # Define gowers distance between two rows, given the ranges of the variables\n",
        "    # over the entire dataset (over all columns in row1 and row2)\n",
        "    def gower_similarity(self, data_row1, data_row2, ranges):\n",
        "        # We cannot computer if the lengths are not equal.\n",
        "        if len(data_row1.columns) != len(data_row2.columns):\n",
        "            return -1\n",
        "\n",
        "        delta_total = 0\n",
        "        s_total = 0\n",
        "\n",
        "        # iterate over all columns.\n",
        "        for i in range(0, len(data_row1.columns)):\n",
        "            val1 = data_row1[data_row1.columns[i]].values[0]\n",
        "            val2 = data_row2[data_row2.columns[i]].values[0]\n",
        "            # compute the delta\n",
        "            delta = self.delta(val1, val2)\n",
        "            delta_total = delta_total + delta\n",
        "            if delta > 0:\n",
        "                # and compute the s if the delta is above 0.\n",
        "                s_total = s_total + self.s(val1, val2, ranges[i])\n",
        "        return float(s_total)/delta_total\n",
        "\n",
        "# Class to flatten datasets or compute the statistical difference between cases.\n",
        "class PersonDistanceMetricsNoOrdering:\n",
        "\n",
        "    gower = 'gower'\n",
        "    minkowski = 'minkowski'\n",
        "\n",
        "    # This returns a dataset with aggregated data instances based on the mean values\n",
        "    # in the rows.\n",
        "    def create_instances_mean(self, datasets):\n",
        "        index = range(0, len(datasets))\n",
        "        cols = datasets[0].columns\n",
        "        new_dataset = pd.DataFrame(index=index, columns=cols)\n",
        "\n",
        "        for i in range(0, len(datasets)):\n",
        "            for col in cols:\n",
        "                # Compute the mean per column and assign that\n",
        "                # value for the row representing the current\n",
        "                # dataset.\n",
        "                new_dataset.iloc[i, new_dataset.columns.get_loc(col)] = datasets[i][col].mean()\n",
        "\n",
        "        return new_dataset\n",
        "\n",
        "    # Fit datasets to normal distribution and use parameters as instances\n",
        "    def create_instances_normal_distribution(self, datasets):\n",
        "        index = range(0, len(datasets))\n",
        "        cols = datasets[0].columns\n",
        "        new_cols = []\n",
        "        # Create new columns for the parameters of the distribution.\n",
        "        for col in cols:\n",
        "            new_cols.append(col + '_mu')\n",
        "            new_cols.append(col + '_sigma')\n",
        "        new_dataset = pd.DataFrame(index=index, columns=new_cols)\n",
        "\n",
        "        for i in range(0, len(datasets)):\n",
        "            for col in cols:\n",
        "                # Fit the distribution and assign the values to the\n",
        "                # row representing the dataset.\n",
        "                mu, sigma = norm.fit(datasets[i][col])\n",
        "                new_dataset.iloc[i, new_dataset.columns.get_loc(col + '_mu')] = mu\n",
        "                new_dataset.iloc[i, new_dataset.columns.get_loc(col + '_sigma')] = sigma\n",
        "\n",
        "        return new_dataset\n",
        "\n",
        "    # This defines the distance between datasets based on the statistical\n",
        "    # differences between the distribution we can only compute\n",
        "    # distances pairwise.\n",
        "    def p_distance(self, dataset1, dataset2):\n",
        "\n",
        "        cols = dataset1.columns\n",
        "        distance = 0\n",
        "        for col in cols:\n",
        "            D, p_value = stats.ks_2samp(dataset1[col], dataset2[col])\n",
        "            distance= distance + (1-p_value)\n",
        "        return distance\n",
        "\n",
        "# Class to compare two time ordered datasets.\n",
        "class PersonDistanceMetricsOrdering:\n",
        "\n",
        "    extreme_value = sys.float_info.max\n",
        "    tiny_value = 0.000001\n",
        "\n",
        "    # Directly pair up the datasets and computer the euclidean\n",
        "    # distances between the sequences of values.\n",
        "    def euclidean_distance(self, dataset1, dataset2):\n",
        "        dist = DistanceMetric.get_metric('euclidean')\n",
        "        if not len(dataset1.index) == len(dataset2.index):\n",
        "            return -1\n",
        "        distance = 0\n",
        "\n",
        "        for i in range(0, len(dataset1.index)):\n",
        "            data_row1 = dataset1.iloc[:,i:i+1].transpose()\n",
        "            data_row2 = dataset2.iloc[:,i:i+1].transpose()\n",
        "            ecl_dist = dist.pairwise(data_row1, data_row2)\n",
        "            distance = distance + ecl_dist\n",
        "\n",
        "        return distance\n",
        "\n",
        "    # Compute the distance between two datasets given a set lag.\n",
        "    def lag_correlation_given_lag(self, dataset1, dataset2, lag):\n",
        "        distance = 0\n",
        "        for i in range(0, len(dataset1.columns)):\n",
        "            # consider the lengths of the series, and compare the\n",
        "            # number of points in the smallest series.\n",
        "            length_ds1 = len(dataset1.index)\n",
        "            length_ds2 = len(dataset2.index) - lag\n",
        "            length_used = min(length_ds1, length_ds2)\n",
        "            if length_used < 1:\n",
        "                return self.extreme_value\n",
        "            # We multiply the values as expressed in the book.\n",
        "            ccc = np.multiply(dataset1.ix[0:length_used, i].values, dataset2.ix[lag:length_used+lag, i].values)\n",
        "            # We add the sum of the mutliplications to the distance. Correct for the difference in length.\n",
        "            distance = distance + (float(1)/(float(max(ccc.sum(), self.tiny_value))))/length_used\n",
        "        return distance\n",
        "\n",
        "    # Compute the lag correlation. For this we find the best lag.\n",
        "    def lag_correlation(self, dataset1, dataset2, max_lag):\n",
        "        best_dist = -1\n",
        "        best_lag = 0\n",
        "        for i in range(0, max_lag+1):\n",
        "            # Compute the distance given a lag.\n",
        "            current_dist = self.lag_correlation_given_lag(dataset1, dataset2, i)\n",
        "            if current_dist < best_dist or best_dist == -1:\n",
        "                best_dist = current_dist\n",
        "                best_lag = i\n",
        "        return best_dist\n",
        "\n",
        "    # Simple implementation of the dtw. Note that we use the euclidean distance here..\n",
        "    # The implementation follows the algorithm explained in the book very closely.\n",
        "    def dynamic_time_warping(self, dataset1, dataset2):\n",
        "        # Create a distance matrix between all time points.\n",
        "        cheapest_path = np.full((len(dataset1.index), len(dataset2.index)), self.extreme_value)\n",
        "        cheapest_path[0,0] = 0\n",
        "        DM = InstanceDistanceMetrics()\n",
        "\n",
        "\n",
        "        for i in range(1, len(dataset1.index)):\n",
        "            for j in range(1, len(dataset2.index)):\n",
        "                data_row1 = dataset1.iloc[i:i+1,:]\n",
        "                data_row2 = dataset2.iloc[j:j+1,:]\n",
        "                d = sklearn.metrics.pairwise.euclidean_distances(data_row1, data_row2)\n",
        "                cheapest_path[i,j] = d + min(cheapest_path[i-1, j], cheapest_path[i, j-1], cheapest_path[i-1, j-1])\n",
        "        return cheapest_path[len(dataset1.index)-1, len(dataset2.index)-1]"
      ],
      "metadata": {
        "id": "ZGX2-Ti2Vnls"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyclust\n",
        "!pip install treelib"
      ],
      "metadata": {
        "id": "gRRPBCZqW7I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b1657c-90de-4513-a7dc-4238ba1f0b44"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyclust\n",
            "  Downloading pyclust-0.2.0.tar.gz (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyclust\n",
            "  Building wheel for pyclust (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyclust: filename=pyclust-0.2.0-py3-none-any.whl size=12805 sha256=f3234eb549c6ddd264188d8ed1fd94e4db21c39fa13773f70390ccb2411563c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f0/e8/66974a70daae12adb25894f145de88ad807763794edcc3b295\n",
            "Successfully built pyclust\n",
            "Installing collected packages: pyclust\n",
            "Successfully installed pyclust-0.2.0\n",
            "Collecting treelib\n",
            "  Downloading treelib-1.6.1.tar.gz (24 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from treelib) (0.16.0)\n",
            "Building wheels for collected packages: treelib\n",
            "  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treelib: filename=treelib-1.6.1-py3-none-any.whl size=18386 sha256=211d993aec7d3374dba60b4a4180de6a39517d9969a283f39c4a8be4894c2458\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/be/94/2c6d949ce599d1443426d83ba4dc93cd35c0f4638260930a53\n",
            "Successfully built treelib\n",
            "Installing collected packages: treelib\n",
            "Successfully installed treelib-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################\n",
        "#                                                            #\n",
        "#    Mark Hoogendoorn and Burkhardt Funk (2017)              #\n",
        "#    Machine Learning for the Quantified Self                #\n",
        "#    Springer                                                #\n",
        "#    Chapter 5                                               #\n",
        "#                                                            #\n",
        "##############################################################\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import random\n",
        "import scipy\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "from sklearn.neighbors import DistanceMetric\n",
        "import pyclust\n",
        "\n",
        "from nltk.cluster.kmeans import KMeansClusterer\n",
        "\n",
        "# Implementation of the non hierarchical clustering approaches.\n",
        "class NonHierarchicalClustering:\n",
        "\n",
        "    # Global parameters for distance functions\n",
        "    p = 1\n",
        "    max_lag = 1\n",
        "\n",
        "    # Identifiers of the various distance and abstraction approaches.\n",
        "    euclidean = 'euclidean'\n",
        "    minkowski = 'minkowski'\n",
        "    manhattan = 'manhattan'\n",
        "    gower = 'gower'\n",
        "    abstraction_mean = 'abstraction_mean'\n",
        "    abstraction_normal = 'abstraction_normal'\n",
        "    abstraction_p = 'abstraction_p'\n",
        "    abstraction_euclidean = 'abstract_euclidean'\n",
        "    abstraction_lag = 'abstract_lag'\n",
        "    abstraction_dtw = 'abstract_dtw'\n",
        "\n",
        "    # Define the gowers distance between arrays to be used in k-means and k-medoids.\n",
        "    def gowers_similarity(self, X, Y=None, Y_norm_squared=None, squared=False):\n",
        "        X = np.matrix(X)\n",
        "        distances = np.zeros(shape=(X.shape[0], Y.shape[0]))\n",
        "        DM = InstanceDistanceMetrics()\n",
        "        # Pairs up the elements in the dataset\n",
        "        for x_row in range(0, X.shape[0]):\n",
        "            data_row1 = pd.DataFrame(X[x_row])\n",
        "            for y_row in range(0, Y.shape[0]):\n",
        "                data_row2 = pd.DataFrame(Y[y_row]).transpose()\n",
        "                # And computer the distance as defined in our distance metrics class.\n",
        "                distances[x_row, y_row] = DM.gowers_similarity(data_row1, data_row2, self.p)\n",
        "        return np.array(distances)\n",
        "\n",
        "    # Use a predefined distance function for the Minkowski distance\n",
        "    def minkowski_distance(self, X, Y=None, Y_norm_squared=None, squared=False):\n",
        "        dist = DistanceMetric.get_metric('minkowski', p=self.p)\n",
        "        return dist.pairwise(X, Y)\n",
        "\n",
        "    # Use a predefined distance function for the Manhattan distance\n",
        "    def manhattan_distance(self, X, Y=None, Y_norm_squared=None, squared=False):\n",
        "        dist = DistanceMetric.get_metric('manhattan')\n",
        "        return dist.pairwise(X, Y)\n",
        "\n",
        "    # Use a predefined distance function for the Euclidean distance\n",
        "    def euclidean_distance(self, X, Y=None, Y_norm_squared=None, squared=False):\n",
        "        dist = DistanceMetric.get_metric('euclidean')\n",
        "        return dist.pairwise(X, Y)\n",
        "\n",
        "    # If we want to compare dataset between persons one approach is to flatten\n",
        "    # each dataset to a single record/instance. This is done based on the approaches\n",
        "    # we have defined in the distance metrics file.\n",
        "    def aggregate_datasets(self, datasets, cols, abstraction_method):\n",
        "        temp_datasets = []\n",
        "        DM = PersonDistanceMetricsNoOrdering()\n",
        "\n",
        "        # Flatten all datasets and add them to the newly formed dataset.\n",
        "        for i in range(0, len(datasets)):\n",
        "            temp_dataset = datasets[i][cols]\n",
        "            temp_datasets.append(temp_dataset)\n",
        "\n",
        "        if abstraction_method == self.abstraction_normal:\n",
        "            return DM.create_instances_normal_distribution(temp_datasets)\n",
        "        else:\n",
        "            return DM.create_instances_mean(temp_datasets)\n",
        "\n",
        "    # Perform k-means over an individual dataset.\n",
        "    def k_means_over_instances(self, dataset, cols, k, distance_metric, max_iters, n_inits, p=1):\n",
        "\n",
        "        # Take the appropriate columns.\n",
        "        temp_dataset = dataset[cols]\n",
        "        # Override the standard distance functions. Store the original first\n",
        "        # sklearn_euclidian_distances = sklearn.cluster.k_means_.euclidean_distances\n",
        "        sklearn_euclidian_distances = sklearn.metrics.pairwise.euclidean_distances\n",
        "        if distance_metric == self.euclidean:\n",
        "            sklearn.metrics.pairwise.euclidean_distances = self.euclidean_distance\n",
        "        elif distance_metric == self.minkowski:\n",
        "            self.p = p\n",
        "            sklearn.metrics.pairwise.euclidean_distances = self.minkowski_distance\n",
        "        elif distance_metric == self.manhattan:\n",
        "            sklearn.metrics.pairwise.euclidean_distances = self.manhattan_distance\n",
        "        elif distance_metric == self.gower:\n",
        "            self.ranges = []\n",
        "            for col in temp_dataset.columns:\n",
        "                self.ranges.append(temp_dataset[col].max() - temp_dataset[col].min())\n",
        "            sklearn.metrics.pairwise.euclidean_distances = self.gower_similarity\n",
        "        # If we do not recognize the option we use the default distance function, which is much\n",
        "        # faster....\n",
        "        # Now apply the k-means algorithm\n",
        "        kmeans = KMeans(n_clusters=k, max_iter=max_iters, n_init=n_inits, random_state=0).fit(temp_dataset)\n",
        "        # Add the labels to the dataset\n",
        "        dataset['cluster'] = kmeans.labels_\n",
        "        # Compute the solhouette and add it as well.\n",
        "        silhouette_avg = silhouette_score(temp_dataset, kmeans.labels_)\n",
        "        silhouette_per_inst = silhouette_samples(temp_dataset, kmeans.labels_)\n",
        "        dataset['silhouette'] = silhouette_per_inst\n",
        "\n",
        "        # Reset the module distance function for further usage\n",
        "        sklearn_euclidian_distances = sklearn_euclidian_distances\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    # We have datasets covering multiple persons. We abstract the datatasets using an approach and create\n",
        "    # clusters of persons.\n",
        "    def k_means_over_datasets(self, datasets, cols, k, abstraction_method, distance_metric, max_iters, n_inits, p=1):\n",
        "        # Convert the datasets to instances\n",
        "        temp_dataset = self.aggregate_datasets(datasets, cols, abstraction_method)\n",
        "\n",
        "        # And simply apply the instance based algorithm.....\n",
        "        return self.k_means_over_instances(temp_dataset, temp_dataset.columns, k, distance_metric, max_iters, n_inits, p)\n",
        "\n",
        "    # For our own k-medoids algorithm we use our own implementation. For this we computer a complete distance matrix\n",
        "    # between points.\n",
        "    def compute_distance_matrix_instances(self, dataset, distance_metric):\n",
        "        # If the distance function is not defined in our distance metrics, we use the standard euclidean distance.\n",
        "        if not (distance_metric in [self.manhattan, self.minkowski, self.gower, self.euclidean]):\n",
        "            distances = sklearn.metrics.pairwise.euclidean_distances(X=dataset, Y=dataset)\n",
        "            return pd.DataFrame(distances, index=range(0, len(dataset.index)), columns=range(0, len(dataset.index)))\n",
        "        # Create an empty pandas dataframe for our distance matrix\n",
        "        distances = pd.DataFrame(index=range(0, len(dataset.index)), columns=range(0, len(dataset.index)))\n",
        "        DM = InstanceDistanceMetrics()\n",
        "\n",
        "        # Define the ranges of the columns if we use the gower distance.\n",
        "        ranges = []\n",
        "        if distance_metric == self.gower:\n",
        "            for col in dataset.columns:\n",
        "                self.ranges.append(dataset[col].max() - dataset[col].min())\n",
        "\n",
        "        # And compute the distances for each pair. Note that we assume the distances to be symmetric.\n",
        "        for i in range(0, len(dataset.index)):\n",
        "            for j in range(i, len(dataset.index)):\n",
        "                if distance_metric == self.manhattan:\n",
        "                    distances.iloc[i,j] = self.manhattan_distance(dataset.iloc[i:i+1,:], dataset.iloc[j:j+1,:])\n",
        "                elif distance_metric == self.minkowski:\n",
        "                    distances.iloc[i,j] = self.manhattan_distance(dataset.iloc[i:i+1,:], dataset.iloc[j:j+1,:], self.p)\n",
        "                elif distance_metric == self.gower:\n",
        "                    distances.iloc[i,j] = self.gowers_similarity(dataset.iloc[i:i+1,:], dataset.iloc[j:j+1,:])\n",
        "                elif distance_metric == self.euclidean:\n",
        "                    distances.iloc[i,j] = self.euclidean_distance(dataset.iloc[i:i+1,:], dataset.iloc[j:j+1,:])\n",
        "                distances.iloc[j,i] = distances.iloc[i,j]\n",
        "        return distances\n",
        "\n",
        "    # We need to implement k-medoids ourselves to accommodate all distance metrics\n",
        "    def k_medoids_over_instances(self, dataset, cols, k, distance_metric, max_iters, n_inits=5, p=1):\n",
        "        # If we set it to default we use the pyclust package...\n",
        "        temp_dataset = dataset[cols]\n",
        "        if distance_metric == 'default':\n",
        "            km = pyclust.KMedoids(n_clusters=k, n_trials=n_inits)\n",
        "            km.fit(temp_dataset.values)\n",
        "            cluster_assignment = km.labels_\n",
        "\n",
        "        else:\n",
        "            print(\"It workds\")\n",
        "            self.p = p\n",
        "            cluster_assignment = []\n",
        "            best_silhouette = -1\n",
        "\n",
        "            # Compute all distances\n",
        "            D = self.compute_distance_matrix_instances(temp_dataset, distance_metric)\n",
        "\n",
        "            for it in range(0, n_inits):\n",
        "                # First select k random points as centers:\n",
        "                centers = random.sample(range(0, len(dataset.index)), k)\n",
        "                prev_centers = []\n",
        "                points_to_cluster = []\n",
        "\n",
        "                n_iter = 0\n",
        "                while (n_iter < max_iters) and not (centers == prev_centers):\n",
        "                    n_iter += 1\n",
        "                    prev_centers = centers\n",
        "                    # Assign points to clusters.\n",
        "                    points_to_centroid = D[centers].idxmin(axis=1)\n",
        "\n",
        "                    new_centers = []\n",
        "                    for i in range(0, k):\n",
        "                    # And find the new center that minimized the sum of the differences.\n",
        "                      \n",
        "                        best_center = D.loc[points_to_centroid == centers[i]].sum().idxmin(axis=1)\n",
        "                        new_centers.append(best_center)\n",
        "                    centers = new_centers\n",
        "\n",
        "                # Convert centroids to cluster numbers:\n",
        "\n",
        "                points_to_centroid = D[centers].idxmin(axis=1)\n",
        "                current_cluster_assignment = []\n",
        "                for i in range(0, len(dataset.index)):\n",
        "                    current_cluster_assignment.append(centers.index(points_to_centroid.iloc[i]))\n",
        "\n",
        "                silhouette_avg = silhouette_score(temp_dataset, np.array(current_cluster_assignment))\n",
        "                if silhouette_avg > best_silhouette:\n",
        "                    cluster_assignment = current_cluster_assignment\n",
        "                    best_silhouette = silhouette_avg\n",
        "\n",
        "        # And add the clusters and silhouette scores to the dataset.\n",
        "        dataset['cluster'] = cluster_assignment\n",
        "        silhouette_avg = silhouette_score(temp_dataset, np.array(cluster_assignment))\n",
        "        silhouette_per_inst = silhouette_samples(temp_dataset, np.array(cluster_assignment))\n",
        "        dataset['silhouette'] = silhouette_per_inst\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    # For k-medoids we use all possible distance metrics between datasets as well. For this we\n",
        "    # again need to define a distance matrix between the datasets.\n",
        "    def compute_distance_matrix_datasets(self, datasets, distance_metric):\n",
        "        distances = pd.DataFrame(index=range(0, len(datasets)), columns=range(0, len(datasets)))\n",
        "        DMNoOrdering = PersonDistanceMetricsNoOrdering()\n",
        "        DMOrdering = PersonDistanceMetricsOrdering()\n",
        "\n",
        "        # And compute the distances for each pair. Note that we assume the distances to be symmetric.\n",
        "        for i in range(0, len(datasets)):\n",
        "            for j in range(i, len(datasets)):\n",
        "                if distance_metric == self.abstraction_p:\n",
        "                    distances.iloc[i,j] = DMNoOrdering.p_distance(datasets[i], datasets[j])\n",
        "                elif distance_metric == self.abstraction_euclidean:\n",
        "                    distances.iloc[i,j] = DMOrdering.euclidean_distance(datasets[i], datasets[j])\n",
        "                elif distance_metric == self.abstraction_lag:\n",
        "                    distances.iloc[i,j] = DMOrdering.lag_correlation(datasets[i], datasets[j], self.max_lag)\n",
        "                elif distance_metric == self.abstraction_dtw:\n",
        "                    distances.iloc[i,j] = DMOrdering.dynamic_time_warping(datasets[i], datasets[j])\n",
        "                distances.iloc[j,i] = distances.iloc[i,j]\n",
        "        return distances\n",
        "\n",
        "    # Note: distance metric only important in combination with certain abstraction methods as we allow for more\n",
        "    # in k-medoids.\n",
        "    def k_medoids_over_datasets(self, datasets, cols, k, abstraction_method, distance_metric, max_iters, n_inits=5, p=1, max_lag=5):\n",
        "        self.p = p\n",
        "        self.max_lag = max_lag\n",
        "\n",
        "        # If we compare datasets by flattening them, we can simply flatten the dataset and apply the instance based\n",
        "        # variant.\n",
        "        if abstraction_method in [self.abstraction_mean, self.abstraction_normal]:\n",
        "            # Convert the datasets to instances\n",
        "            temp_dataset = self.aggregate_datasets(datasets, cols, abstraction_method)\n",
        "\n",
        "            # And simply apply the instance based algorithm in case of\n",
        "            return self.k_medoids_over_instances(temp_dataset, temp_dataset.columns, k, distance_metric, max_iters, n_inits=n_inits, p=p)\n",
        "\n",
        "        # For the case over datasets we do not have a quality metric, therefore we just look at a single initialization for now (!)\n",
        "\n",
        "        # First select k random points as centers:\n",
        "        centers = random.sample(range(0, len(datasets)), k)\n",
        "        prev_centers = []\n",
        "        points_to_cluster = []\n",
        "        # Compute all distances\n",
        "        D = self.compute_distance_matrix_datasets(datasets, abstraction_method)\n",
        "\n",
        "        n_iter = 0\n",
        "        while (n_iter < max_iters) and not (centers == prev_centers):\n",
        "            n_iter += 1\n",
        "            prev_centers = centers\n",
        "            # Assign points to clusters.\n",
        "            points_to_centroid = D[centers].idxmin(axis=1)\n",
        "\n",
        "            new_centers = []\n",
        "            for i in range(0, k):\n",
        "                # And find the new center that minimized the sum of the differences.\n",
        "                best_center = D.loc[points_to_centroid == centers[i], points_to_centroid == centers[i]].sum().idxmin(axis=1)\n",
        "                new_centers.append(best_center)\n",
        "            centers = new_centers\n",
        "\n",
        "        # Convert centroids to cluster numbers:\n",
        "\n",
        "        points_to_centroid = D[centers].idxmin(axis=1)\n",
        "        cluster_assignment = []\n",
        "        for i in range(0, len(datasets)):\n",
        "            cluster_assignment.append(centers.index(points_to_centroid.iloc[i,:]))\n",
        "\n",
        "        dataset = pd.DataFrame(index=range(0, len(datasets)))\n",
        "        dataset['cluster'] = cluster_assignment\n",
        "\n",
        "        # Silhouette cannot be used here as it used a distance between instances, not datasets.\n",
        "\n",
        "        return dataset\n",
        "\n",
        "# In this class, we do not implement the Gover distance between instance, all others are included.\n",
        "# Furthermore, we only implement the agglomerative approach.\n",
        "class HierarchicalClustering:\n",
        "\n",
        "    link = None\n",
        "\n",
        "    # Perform agglomerative clustering over a single dataset.\n",
        "    def agglomerative_over_instances(self, dataset, cols, max_clusters, distance_metric, use_prev_linkage=False, link_function='single'):\n",
        "        temp_dataset = dataset[cols]\n",
        "        df = NonHierarchicalClustering()\n",
        "\n",
        "        if (not use_prev_linkage) or (self.link is None):\n",
        "            # Perform the clustering process according to the specified distance metric.\n",
        "            if distance_metric == df.manhattan:\n",
        "                self.link = linkage(temp_dataset.values, method=link_function, metric='cityblock')\n",
        "            else:\n",
        "                self.link = linkage(temp_dataset.values, method=link_function, metric='euclidean')\n",
        "\n",
        "        # And assign the clusters given the set maximum. In addition, compute the\n",
        "        cluster_assignment = fcluster(self.link, max_clusters, criterion='maxclust')\n",
        "        dataset['cluster'] = cluster_assignment\n",
        "        silhouette_avg = silhouette_score(temp_dataset, np.array(cluster_assignment))\n",
        "        silhouette_per_inst = silhouette_samples(temp_dataset, np.array(cluster_assignment))\n",
        "        dataset['silhouette'] = silhouette_per_inst\n",
        "\n",
        "        return dataset, self.link\n",
        "\n",
        "    # Perform agglomerative clustering over the datasets by flattening them into a single dataset.\n",
        "    def agglomerative_over_datasets(self, datasets, cols, max_clusters, abstraction_method, distance_metric, use_prev_linkage=False, link_function='single'):\n",
        "        # Convert the datasets to instances\n",
        "        df = NonHierarchicalClustering()\n",
        "        temp_dataset = df.aggregate_datasets(datasets, cols, abstraction_method)\n",
        "\n",
        "        # And simply apply the instance based algorithm...\n",
        "        return self.agglomerative_over_instances(temp_dataset, temp_dataset.columns, max_clusters, distance_metric, use_prev_linkage=use_prev_linkage, link_function=link_function)"
      ],
      "metadata": {
        "id": "2OqdXoBVVrLe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sum_of_squared_distances = []\n",
        "K = range(2,500, 5)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km = km.fit(space[['Kalium (bloed)', 'ABP gemiddeld', 'Kreatinine (bloed)', 'Natrium (bloed)', 'UrineCAD', 'UrineSupraPubis', 'UrineSpontaan',\n",
        " 'UrineUP',\n",
        " 'Kreatinine',\n",
        " 'Nefrodrain re Uit',\n",
        " 'Nefrodrain li Uit',\n",
        " 'UrineIncontinentie',\n",
        " 'gender_Vrouw',\n",
        " 'agegroup',\n",
        " 'AKI']])\n",
        "    Sum_of_squared_distances.append(km.inertia_)\n",
        "\n",
        "plt.plot(K, Sum_of_squared_distances, 'b-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum_of_squared_distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ymjGZNW5W1l9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import copy\n",
        "\n",
        "# DataViz = VisualizeDataset()\n",
        "\n",
        "# clusteringNH = NonHierarchicalClustering()\n",
        "# clusteringH = HierarchicalClustering()\n",
        "\n",
        "# # Let us look at k-means first.\n",
        "# k_values = range(100, 400, 20)\n",
        "# silhouette_values = []\n",
        "\n",
        "# # Do some initial runs to determine the right number for k\n",
        "\n",
        "# print('===== kmeans clustering =====')\n",
        "# for k in k_values:\n",
        "#     print(f'k = {k}')\n",
        "#     dataset_cluster = clusteringNH.k_means_over_instances(copy.deepcopy(\n",
        "#         space), ['Kalium (bloed)', 'ABP gemiddeld', 'Kreatinine (bloed)', 'Natrium (bloed)', 'UrineCAD', 'UrineSupraPubis', 'UrineSpontaan',\n",
        "#  'UrineUP',\n",
        "#  'Kreatinine',\n",
        "#  'Nefrodrain re Uit',\n",
        "#  'Nefrodrain li Uit',\n",
        "#  'UrineIncontinentie',\n",
        "#  'gender_Vrouw',\n",
        "#  'agegroup',\n",
        "#  'AKI'], k, 'default', 20, 10)\n",
        "#     silhouette_score_n = dataset_cluster['silhouette'].mean()\n",
        "#     print(f'silhouette = {silhouette_score_n}')\n",
        "#     silhouette_values.append(silhouette_score_n)\n",
        "\n",
        "# DataViz.plot_xy(x=[k_values], y=[silhouette_values], xlabel='k', ylabel='silhouette score',\n",
        "#                 ylim=[0, 1], line_styles=['b-'])\n",
        "\n",
        "# # And run the knn with the highest silhouette score\n",
        "\n",
        "# k = k_values[np.argmax(silhouette_values)]\n",
        "# print(f'Highest K-Means silhouette score: k = {k}')\n",
        "# print('Use this value of k to run the --mode=final --k=?')"
      ],
      "metadata": {
        "id": "YfnEQAEkXdJe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjxgeewKJsHO"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "def k_means_over_instances(dataset, cols, k, max_iters, n_inits):\n",
        "\n",
        "        # Take the appropriate columns.\n",
        "        temp_dataset = dataset[cols]\n",
        "        # Now apply the k-means algorithm\n",
        "        kmeans = KMeans(n_clusters=k, max_iter=max_iters, n_init=n_inits, random_state=0).fit(temp_dataset)\n",
        "        # Add the labels to the dataset\n",
        "        dataset['cluster'] = kmeans.labels_\n",
        "        # Compute the solhouette and add it as well.\n",
        "        silhouette_avg = silhouette_score(temp_dataset, kmeans.labels_)\n",
        "        silhouette_per_inst = silhouette_samples(temp_dataset, kmeans.labels_)\n",
        "        dataset['silhouette'] = silhouette_per_inst\n",
        "\n",
        "        return dataset, silhouette_avg"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeMog-8kS_HY"
      },
      "source": [
        "# Use k=50 based on previous runs\n",
        "\n",
        "new_d, sil = k_means_over_instances(space, ['Kalium (bloed)', 'ABP gemiddeld', 'Kreatinine (bloed)', 'Natrium (bloed)', 'UrineCAD', 'UrineSupraPubis', 'UrineSpontaan',\n",
        " 'UrineUP',\n",
        " 'Kreatinine',\n",
        " 'Nefrodrain re Uit',\n",
        " 'Nefrodrain li Uit',\n",
        " 'UrineIncontinentie',\n",
        " 'gender_Vrouw',\n",
        " 'agegroup',\n",
        " 'AKI'], 50, 20, 10)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binning Values\n",
        "\n",
        "binsv = [-np.inf, new_d['Noradrenaline (Norepinefrine)'].median(), np.inf]\n",
        "binsf = [-np.inf, new_d['NaCl 0,45%/Glucose 2,5%'].median(), np.inf]\n",
        "labels = [0, 1]\n",
        "new_d['vasop'] = pd.cut(new_d['Noradrenaline (Norepinefrine)'], bins=binsv, labels=labels)\n",
        "new_d['fluid'] = pd.cut(new_d['NaCl 0,45%/Glucose 2,5%'], bins=binsf, labels=labels)"
      ],
      "metadata": {
        "id": "UHX0jCShikHm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = low vasop, high fluid\n",
        "# 1 = high vasop, low fluid\n",
        "# 2 = same levels of low\n",
        "# 3 = same levels of high\n",
        "\n",
        "act = []\n",
        "\n",
        "for v, f in zip(new_d['vasop'], new_d['fluid']): \n",
        "  if v == 0 and f == 1: act.append('0')\n",
        "  elif v == 1 and f == 0: act.append('1')\n",
        "  elif v == 0 and f == 0: act.append('2')\n",
        "  elif v == 1 and f == 1: act.append('3')\n",
        "\n",
        "new_d['action'] = act"
      ],
      "metadata": {
        "id": "ILSCKlLclnlv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_d['reward'] = -new_d['AKI']"
      ],
      "metadata": {
        "id": "Xi--EySntt4x"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_d['next'] = new_d['cluster'].shift(-1)"
      ],
      "metadata": {
        "id": "XvCtBdJ_t8RH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = new_d.dropna()"
      ],
      "metadata": {
        "id": "5oWVkN-ry8Vz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmjud5yRK9e0"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Transition Matrix\n",
        "\n",
        "# # Counting number of unique clusters (now we know it, but for later if we add more might be useful)\n",
        "\n",
        "# numbers = sorted(final['cluster'].unique())\n",
        "\n",
        "# # Find how many times a state is followed by another\n",
        "\n",
        "# groups = final.groupby(['cluster', 'next'])\n",
        "# counts = {i[0]:(len(i[1]) if i[0][0] != i[0][1] else 0) for i in groups} \n",
        "\n",
        "# # Build a matrix based on the counts just performed\n",
        "\n",
        "# matrix = pd.DataFrame()\n",
        "\n",
        "# for x in numbers:\n",
        "#     matrix[x] = pd.Series([counts.get((x,y), 0) for y in numbers], index=numbers)\n",
        "  \n",
        "# matrix_normed = matrix / matrix.sum(axis=0)\n",
        "# matrix = matrix_normed.to_numpy()\n",
        "# print(matrix)"
      ],
      "metadata": {
        "id": "3ZmXf1wulkKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many times a state is associated with a certain reward\n",
        "\n",
        "# For now, it might make sense to model the reward of each state based on the highest number of occurrences of a certain reward\n",
        "\n",
        "# rewards = final.groupby(['cluster', 'reward']).size()\n",
        "# print(rewards)\n",
        "\n",
        "rewards = final.groupby(['cluster'], sort=False)['reward'].max()\n",
        "rewards.sort_index(inplace=True)\n",
        "rewards = rewards.to_numpy()"
      ],
      "metadata": {
        "id": "T1W93Qg_oUN6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rew = final.groupby(['cluster', 'action', 'next']).size()\n",
        "# # rew.sort_index(inplace=True)\n",
        "# print(rew)\n",
        "# # rew = rew.to_numpy()"
      ],
      "metadata": {
        "id": "fe7hWsUL25h-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd14268d-a68d-4a4b-ad70-e2f66317568c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cluster  action  next\n",
            "0        0       0.0     126\n",
            "                 2.0       1\n",
            "                 8.0       1\n",
            "                 10.0      1\n",
            "                 14.0      1\n",
            "                        ... \n",
            "49       2       8.0       3\n",
            "                 49.0     53\n",
            "         3       7.0       1\n",
            "                 43.0      1\n",
            "                 49.0     34\n",
            "Length: 1741, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alphas = range(0, 85, 5)  # Learning Rate\n",
        "# gamma = 0.99 # Discount Factor\n",
        "\n",
        "# for alpha in alphas:\n",
        "\n",
        "#   alpha = alpha/100\n",
        "#   val = []\n",
        "  \n",
        "#   # Q(s, a) matrix\n",
        "\n",
        "#   for i in range(10):\n",
        "\n",
        "#     Q = np.zeros((50, 4))\n",
        "\n",
        "#     from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "#     train_inds, test_inds = GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 7).split(final, groups=final['admissionid'])\n",
        "\n",
        "#     train = final.iloc[train_inds[0]]\n",
        "#     test = final.iloc[test_inds[0]]\n",
        "\n",
        "#     iterations = 1000000\n",
        "\n",
        "#     train = train[['cluster', 'action', 'next', 'reward']].sample(n = iterations, replace = True)\n",
        "#     test = test[['cluster', 'action', 'next', 'reward']].sample(n = iterations, replace = True)\n",
        "#     i = 0\n",
        "\n",
        "#     for row in train.loc[:,['cluster', 'action', 'next', 'reward']].itertuples():\n",
        "#       index, curr, act, next, rew = row\n",
        "#       delta = rew+gamma*np.max(Q[int(next), :])- Q[int(curr), int(act)]\n",
        "#       Q[int(curr), int(act)] += alpha*delta\n",
        "#       i += 1\n",
        "#       # if the update is smaller than a certain threshold, stop the iteration\n",
        "\n",
        "#       # if delta < 1e-10: break\n",
        "\n",
        "#     p_optim = 0.9\n",
        "\n",
        "#     actions = np.argmax(Q, axis = 1)\n",
        "#     pi = np.full((50, 4), ((1-p_optim)/(50-1)))\n",
        "#     for i, j in enumerate(actions):\n",
        "#       pi[i,j] = p_optim\n",
        "\n",
        "#     Q_1 = np.zeros((50, 4))\n",
        "\n",
        "#     for row in test.loc[:,['cluster', 'action', 'next', 'reward']].itertuples():\n",
        "#       index, curr, act, next, rew = row\n",
        "#       Q_1[int(curr), int(act)] += 1\n",
        "\n",
        "#     Q_1 = Q_1/Q_1.sum(axis=1, keepdims=True)\n",
        "\n",
        "#     best_act_pi = np.argmax(Q, axis=1)\n",
        "#     best_act_test = np.argmax(Q_1, axis=1)\n",
        "\n",
        "#     val.append(np.count_nonzero(best_act_pi == best_act_test))\n",
        "\n",
        "#   val = np.array(val)\n",
        "#   print(alpha, val.mean())"
      ],
      "metadata": {
        "id": "h4retGrtcA2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter Tuning"
      ],
      "metadata": {
        "id": "61FlQv3qOEx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = range(0, 85, 5)  # Learning Rate\n",
        "gamma = 0.99 # Discount Factor\n",
        "\n",
        "for alpha in alphas:\n",
        "\n",
        "  alpha = alpha/100\n",
        "\n",
        "  Q = np.zeros((50, 4))\n",
        "\n",
        "  from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "  train_inds, test_inds = GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 7).split(final, groups=final['admissionid'])\n",
        "\n",
        "  train = final.iloc[train_inds[0]]\n",
        "  test = final.iloc[test_inds[0]]\n",
        "\n",
        "  iterations = 1000000\n",
        "\n",
        "  train = train[['cluster', 'action', 'next', 'reward']].sample(n = iterations, replace = True)\n",
        "  test = test[['cluster', 'action', 'next', 'reward']].sample(n = iterations, replace = True)\n",
        "  i = 0\n",
        "\n",
        "  for row in train.loc[:,['cluster', 'action', 'next', 'reward']].itertuples():\n",
        "    index, curr, act, next, rew = row\n",
        "    delta = rew+gamma*np.max(Q[int(next), :])- Q[int(curr), int(act)]\n",
        "    Q[int(curr), int(act)] += alpha*delta\n",
        "    i += 1\n",
        "    # if the update is smaller than a certain threshold, stop the iteration\n",
        "\n",
        "    # if delta < 1e-10: break\n",
        "\n",
        "  p_optim = 0.9\n",
        "\n",
        "  actions = np.argmax(Q, axis = 1)\n",
        "  pi = np.full((50, 4), ((1-p_optim)/(50-1)))\n",
        "  for i, j in enumerate(actions):\n",
        "    pi[i,j] = p_optim\n",
        "\n",
        "  Q_1 = np.zeros((50, 4))\n",
        "\n",
        "  for row in test.loc[:,['cluster', 'action', 'next', 'reward']].itertuples():\n",
        "    index, curr, act, next, rew = row\n",
        "    Q_1[int(curr), int(act)] += 1\n",
        "\n",
        "  Q_1 = Q_1/Q_1.sum(axis=1, keepdims=True)\n",
        "\n",
        "  best_act_pi = np.argmax(Q, axis=1)\n",
        "  best_act_test = np.argmax(Q_1, axis=1)\n",
        "\n",
        "  print(alpha, np.count_nonzero(best_act_pi == best_act_test))"
      ],
      "metadata": {
        "id": "YPBGfK4c-2Mz"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the Model, Optimal Parameters"
      ],
      "metadata": {
        "id": "uRCFHf5CRKpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "train_inds, test_inds = GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 7).split(final, groups=final['admissionid'])\n",
        "\n",
        "train = final.iloc[train_inds[0]]\n",
        "test = final.iloc[test_inds[0]]\n",
        "\n",
        "train = train[['cluster', 'action', 'next', 'reward']].sample(n = iterations, replace = True)\n",
        "test = test[['cluster', 'action', 'next', 'reward']].sample(n = iterations, replace = True)\n",
        "\n",
        "alphas = 0.75  # Learning Rate\n",
        "gamma = 0.99 # Discount Factor\n",
        "\n",
        "avg_Q = []\n",
        "avg_Q1 = []\n",
        "\n",
        "for i in range(50):\n",
        "\n",
        "  Q = np.zeros((50, 4))\n",
        "\n",
        "  iterations = 1000000\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  for row in train.loc[:,['cluster', 'action', 'next', 'reward']].itertuples():\n",
        "    index, curr, act, next, rew = row\n",
        "    delta = rew+gamma*np.max(Q[int(next), :])- Q[int(curr), int(act)]\n",
        "    Q[int(curr), int(act)] += alphas*delta\n",
        "    i += 1\n",
        "    # if the update is smaller than a certain threshold, stop the iteration\n",
        "\n",
        "    # if delta < 1e-10: break\n",
        "\n",
        "  p_optim = 0.9\n",
        "\n",
        "  actions = np.argmax(Q, axis = 1)\n",
        "  pi = np.full((50, 4), ((1-p_optim)/(50-1)))\n",
        "  for i, j in enumerate(actions):\n",
        "    pi[i,j] = p_optim\n",
        "\n",
        "  avg_Q.append(np.average(pi, axis=0))  "
      ],
      "metadata": {
        "id": "-6oqPFua0JlN"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_Q1 = []\n",
        "\n",
        "for i in range(10):\n",
        "  Q_1 = np.zeros((50, 4))\n",
        "\n",
        "  for row in test.loc[:,['cluster', 'action', 'next', 'reward']].itertuples():\n",
        "    index, curr, act, next, rew = row\n",
        "    Q_1[int(curr), int(act)] += 1\n",
        "\n",
        "  Q_1 = Q_1/Q_1.sum(axis=1, keepdims=True)\n",
        "\n",
        "  best_act_pi = np.argmax(Q, axis=1)\n",
        "  best_act_test = np.argmax(Q_1, axis=1)\n",
        "\n",
        "  avg_Q1.append(np.average(Q_1, axis = 0))"
      ],
      "metadata": {
        "id": "BlzFswA60gMS"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q_plot = np.average(pi, axis=0)\n",
        "Q_1_plot = np.average(Q_1, axis = 0)\n",
        "\n",
        "Q_plot, Q_1_plot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53iEPX7nEBaL",
        "outputId": "3414cda9-9133-4afe-f354-405f17cdff9b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.9       , 0.00204082, 0.00204082, 0.00204082]),\n",
              " array([0.23896946, 0.23915321, 0.26549819, 0.25637914]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.count_nonzero(best_act_pi == best_act_test)"
      ],
      "metadata": {
        "id": "qxXcCTBz_bmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['0', '1', '2', '3']\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, Q_plot, width, label='Algorithm Policy')\n",
        "rects2 = ax.bar(x + width/2, Q_1_plot, width, label='Test Set Actions')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Probability of Taking Action')\n",
        "ax.set_title('Action')\n",
        "ax.set_xticks([0, 1, 2, 3])\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UF0C_Jzi57_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating differences between bar plots"
      ],
      "metadata": {
        "id": "Uu48ipX4RRJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro, ttest_ind, ks_2samp\n",
        "\n",
        "avg_Q = np.array(avg_Q)\n",
        "avg_Q1 = np.array(avg_Q1)\n",
        "\n",
        "for i in range(4):\n",
        "\n",
        "  stat, p = shapiro(avg_Q[:, i])\n",
        "  stats, q = shapiro(avg_Q1[:, i])\n",
        "  print('----------------------------------------------------')\n",
        "  print('avg1: Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "  print('avg2: Statistics=%.3f, p=%.3f' % (stats, q))\n",
        "\n",
        "  alpha = 0.05\n",
        "  if p > alpha and q > alpha:\n",
        "      print('----------------------------------------------------')\n",
        "      print('YES Gaussian: (fail to reject H0), therefore apply 2 sample ttest')\n",
        "      print('2 sample independent ttest: ' + str(ttest_ind(avg_Q[:, i], avg_Q1[:, i]))) \n",
        "      print('----------------------------------------------------')\n",
        "  else:\n",
        "      print('----------------------------------------------------')\n",
        "      print('NOT Gaussian: (reject H0), therefore apply KS')\n",
        "      #for 2 independent samples with non-normal distribution. H0 > 2 populations are the same\n",
        "      # print(type(avg_Q))\n",
        "      # avg_1_ = avg_1.iloc[:,1]\n",
        "      # avg_2_ = avg_2.iloc[:,1]\n",
        "      # print(type(avg_Q1))\n",
        "      print(ks_2samp(avg_Q[:, i], avg_Q1[:, i])) \n",
        "\n",
        "      print('----------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK83R7aS7Fmx",
        "outputId": "9d5d7950-5ede-4d2d-95a3-29096d5e2661"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------\n",
            "avg1: Statistics=1.000, p=1.000\n",
            "avg2: Statistics=1.000, p=1.000\n",
            "----------------------------------------------------\n",
            "YES Gaussian: (fail to reject H0), therefore apply 2 sample ttest\n",
            "2 sample independent ttest: Ttest_indResult(statistic=inf, pvalue=0.0)\n",
            "----------------------------------------------------\n",
            "----------------------------------------------------\n",
            "avg1: Statistics=1.000, p=1.000\n",
            "avg2: Statistics=1.000, p=1.000\n",
            "----------------------------------------------------\n",
            "YES Gaussian: (fail to reject H0), therefore apply 2 sample ttest\n",
            "2 sample independent ttest: Ttest_indResult(statistic=-809292098893506.5, pvalue=0.0)\n",
            "----------------------------------------------------\n",
            "----------------------------------------------------\n",
            "avg1: Statistics=1.000, p=1.000\n",
            "avg2: Statistics=1.000, p=1.000\n",
            "----------------------------------------------------\n",
            "YES Gaussian: (fail to reject H0), therefore apply 2 sample ttest\n",
            "2 sample independent ttest: Ttest_indResult(statistic=-9411783043980888.0, pvalue=0.0)\n",
            "----------------------------------------------------\n",
            "----------------------------------------------------\n",
            "avg1: Statistics=1.000, p=1.000\n",
            "avg2: Statistics=1.000, p=1.000\n",
            "----------------------------------------------------\n",
            "YES Gaussian: (fail to reject H0), therefore apply 2 sample ttest\n",
            "2 sample independent ttest: Ttest_indResult(statistic=-4467953692290422.5, pvalue=0.0)\n",
            "----------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/morestats.py:1673: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
            "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
          ]
        }
      ]
    }
  ]
}